{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd076c0-dd88-43f1-819f-bcd83e8b53eb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af3ecf0-9659-4e60-92ea-e70978f75ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install opencv-python-headless\n",
    "# %pip install scikit-image\n",
    "# %pip install basic-image-eda\n",
    "# %pip install seaborn\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bd4a1d-1ead-4a16-9df9-853b1388aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mp_image\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec757f59-bfeb-4fd5-a3a8-52a79aac39fb",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6a74e9-a024-45c6-ac57-6bc1460956eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 23\n",
      "Total num train images: 15557\n",
      "Total num test images: 4003\n",
      "                                                Class  Train  Test\n",
      "0                             Acne and Rosacea Photos    840   313\n",
      "1   Actinic Keratosis Basal Cell Carcinoma and oth...   1149   288\n",
      "2                            Atopic Dermatitis Photos    489   123\n",
      "3                              Bullous Disease Photos    448   113\n",
      "4   Cellulitis Impetigo and other Bacterial Infect...    288    73\n",
      "5                                       Eczema Photos   1235   309\n",
      "6                        Exanthems and Drug Eruptions    404   101\n",
      "7   Hair Loss Photos Alopecia and other Hair Diseases    239    60\n",
      "8                    Herpes HPV and other STDs Photos    405   102\n",
      "9        Light Diseases and Disorders of Pigmentation    568   143\n",
      "10         Lupus and other Connective Tissue diseases    420   105\n",
      "11                Melanoma Skin Cancer Nevi and Moles    463   116\n",
      "12                 Nail Fungus and other Nail Disease   1040   261\n",
      "13     Poison Ivy Photos and other Contact Dermatitis    260    65\n",
      "14  Psoriasis pictures Lichen Planus and related d...   1405   352\n",
      "15  Scabies Lyme Disease and other Infestations an...    431   108\n",
      "16       Seborrheic Keratoses and other Benign Tumors   1371   343\n",
      "17                                   Systemic Disease    606   152\n",
      "18  Tinea Ringworm Candidiasis and other Fungal In...   1300   325\n",
      "19                                    Urticaria Hives    212    53\n",
      "20                                    Vascular Tumors    482   121\n",
      "21                                  Vasculitis Photos    416   105\n",
      "22         Warts Molluscum and other Viral Infections   1086   272\n"
     ]
    }
   ],
   "source": [
    "# credits: https://github.com/yuliyabohdan/Skin-diseases-classification-Dermnet-/blob/main/skin_diseases_clas_ResNet50.ipynb\n",
    "\n",
    "DIR = 'dermnet'\n",
    "DIR_TRAIN = f'{DIR}/train/'\n",
    "DIR_TEST = f'{DIR}/test/'\n",
    "\n",
    "classes = os.listdir(DIR_TRAIN)\n",
    "print(f'Total classes: {len(classes)}')\n",
    "\n",
    "# total train and test images\n",
    "train_count = 0\n",
    "test_count = 0\n",
    "\n",
    "classes_df = []\n",
    "for _class in classes:\n",
    "    class_dict = {}\n",
    "    train_count += len(os.listdir(DIR_TRAIN + _class))\n",
    "    test_count += len(os.listdir(DIR_TEST + _class))\n",
    "    class_dict.update({'Class': _class, \n",
    "                       'Train': len(os.listdir(DIR_TRAIN + _class)), \n",
    "                       'Test': len(os.listdir(DIR_TEST + _class)) })\n",
    "    classes_df.append(class_dict)\n",
    "\n",
    "print(f'Total num train images: {train_count}')\n",
    "print(f'Total num test images: {test_count}')\n",
    "print(pd.DataFrame(classes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd1f6f2f-b8b5-49fb-b964-7f29ab70e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acne and Rosacea Photos': 0,\n",
       " 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions': 1,\n",
       " 'Atopic Dermatitis Photos': 2,\n",
       " 'Bullous Disease Photos': 3,\n",
       " 'Cellulitis Impetigo and other Bacterial Infections': 4,\n",
       " 'Eczema Photos': 5,\n",
       " 'Exanthems and Drug Eruptions': 6,\n",
       " 'Hair Loss Photos Alopecia and other Hair Diseases': 7,\n",
       " 'Herpes HPV and other STDs Photos': 8,\n",
       " 'Light Diseases and Disorders of Pigmentation': 9,\n",
       " 'Lupus and other Connective Tissue diseases': 10,\n",
       " 'Melanoma Skin Cancer Nevi and Moles': 11,\n",
       " 'Nail Fungus and other Nail Disease': 12,\n",
       " 'Poison Ivy Photos and other Contact Dermatitis': 13,\n",
       " 'Psoriasis pictures Lichen Planus and related diseases': 14,\n",
       " 'Scabies Lyme Disease and other Infestations and Bites': 15,\n",
       " 'Seborrheic Keratoses and other Benign Tumors': 16,\n",
       " 'Systemic Disease': 17,\n",
       " 'Tinea Ringworm Candidiasis and other Fungal Infections': 18,\n",
       " 'Urticaria Hives': 19,\n",
       " 'Vascular Tumors': 20,\n",
       " 'Vasculitis Photos': 21,\n",
       " 'Warts Molluscum and other Viral Infections': 22}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map class labels to integer index\n",
    "\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(DIR_TRAIN + _class):\n",
    "        train_imgs.append(f'{DIR_TRAIN}{_class}/{img}')\n",
    "    \n",
    "    for img in os.listdir(DIR_TEST + _class):\n",
    "        test_imgs.append(f'{DIR_TEST}{_class}/{img}')\n",
    "\n",
    "classToInt = {classes[i]: i for i in range(len(classes))}\n",
    "intToClass = dict(map(reversed, classToInt.items()))\n",
    "classToInt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e2800-07ab-4767-a5dd-dc9c8df7e36d",
   "metadata": {},
   "source": [
    "# Data Split/Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caaf5173-414d-42be-bf1b-1232934451d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = DIR_TRAIN, transform=transforms.Compose([\n",
    "    transforms.RandomRotation([-8, +8]),                                           # if augmentation\n",
    "    transforms.ColorJitter(brightness=0, contrast=0.4, saturation=0, hue=0),      # if augmentation\n",
    "    transforms.RandomHorizontalFlip(),                                            # if augmentation\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))\n",
    "test_dataset = ImageFolder(root = DIR_TEST, transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e477d24-6b26-4399-8d1c-740b258b1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.5 * len(test_dataset))\n",
    "valid_size = len(test_dataset) - test_size\n",
    "valid_dataset, test_dataset = torch.utils.data.random_split(test_dataset, \n",
    "                                                            [valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159f120-456e-440d-b49c-34981e4fb946",
   "metadata": {},
   "source": [
    "# Train/Val Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9580d1e6-e22f-4f95-8a0a-3e4fb9948ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "dataloaders_dict['val'] = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a6e65-be27-435e-8838-8abcdb4eb42a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ecf8668-ae95-425a-86fb-41d2dc1118e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:               \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                #update_bn_stats(model=model, data_loader=dataloaders[phase])  # if update_bn_stats\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                      # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "               # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "   \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2e3726-0651-4508-935a-7dd3d45115bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f\"Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}\")    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c48bc1c-c03b-4131-93bd-9028b30873d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y - find the img from class x labelled as class y \n",
    "def test(model, dl, x, y, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    images_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images_list.append(images.cpu().numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "    \n",
    "    for n in range(60):\n",
    "        for i in range(32):\n",
    "            if (true_labels[n][i] == x)  & (predictions[n][i] == y):\n",
    "                #inv_tensor = inv_normalize(image_list[n][i]])\n",
    "                plt.imshow(np.transpose(images_list[n][i], (1, 2, 0)))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28f8998-757b-48cd-9d27-b11c2433632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 100\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 23, bias=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db7995-9435-4cdb-9595-6a572cf8b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 2.1875 Acc: 0.3517\n",
      "val Loss: 1.8816 Acc: 0.4383\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 1.7020 Acc: 0.4938\n",
      "val Loss: 1.6336 Acc: 0.5052\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 1.4062 Acc: 0.5709\n",
      "val Loss: 1.5291 Acc: 0.5457\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 1.1580 Acc: 0.6450\n",
      "val Loss: 1.4982 Acc: 0.5686\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.9467 Acc: 0.7057\n",
      "val Loss: 1.4336 Acc: 0.5991\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.7651 Acc: 0.7627\n",
      "val Loss: 1.4701 Acc: 0.5936\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.7965\n",
      "val Loss: 1.4614 Acc: 0.6071\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.5195 Acc: 0.8334\n",
      "val Loss: 1.5462 Acc: 0.6106\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.4527 Acc: 0.8544\n",
      "val Loss: 1.5381 Acc: 0.5986\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.3964 Acc: 0.8710\n",
      "val Loss: 1.4657 Acc: 0.6261\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.3465 Acc: 0.8846\n",
      "val Loss: 1.5840 Acc: 0.6201\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.3202 Acc: 0.8919\n",
      "val Loss: 1.5626 Acc: 0.6161\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.2861 Acc: 0.9081\n",
      "val Loss: 1.6955 Acc: 0.6186\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.2901 Acc: 0.9008\n",
      "val Loss: 1.6936 Acc: 0.6091\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.2596 Acc: 0.9123\n",
      "val Loss: 1.7495 Acc: 0.6126\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ece5f9-f83a-4e8a-8bda-90a9c2d090a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
