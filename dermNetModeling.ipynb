{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd076c0-dd88-43f1-819f-bcd83e8b53eb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af3ecf0-9659-4e60-92ea-e70978f75ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install opencv-python-headless\n",
    "# %pip install scikit-image\n",
    "# %pip install basic-image-eda\n",
    "# %pip install seaborn\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bd4a1d-1ead-4a16-9df9-853b1388aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mp_image\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec757f59-bfeb-4fd5-a3a8-52a79aac39fb",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6a74e9-a024-45c6-ac57-6bc1460956eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 23\n",
      "Total num train images: 15557\n",
      "Total num test images: 4003\n",
      "                                                Class  Train  Test\n",
      "0                             Acne and Rosacea Photos    840   313\n",
      "1   Actinic Keratosis Basal Cell Carcinoma and oth...   1149   288\n",
      "2                            Atopic Dermatitis Photos    489   123\n",
      "3                              Bullous Disease Photos    448   113\n",
      "4   Cellulitis Impetigo and other Bacterial Infect...    288    73\n",
      "5                                       Eczema Photos   1235   309\n",
      "6                        Exanthems and Drug Eruptions    404   101\n",
      "7   Hair Loss Photos Alopecia and other Hair Diseases    239    60\n",
      "8                    Herpes HPV and other STDs Photos    405   102\n",
      "9        Light Diseases and Disorders of Pigmentation    568   143\n",
      "10         Lupus and other Connective Tissue diseases    420   105\n",
      "11                Melanoma Skin Cancer Nevi and Moles    463   116\n",
      "12                 Nail Fungus and other Nail Disease   1040   261\n",
      "13     Poison Ivy Photos and other Contact Dermatitis    260    65\n",
      "14  Psoriasis pictures Lichen Planus and related d...   1405   352\n",
      "15  Scabies Lyme Disease and other Infestations an...    431   108\n",
      "16       Seborrheic Keratoses and other Benign Tumors   1371   343\n",
      "17                                   Systemic Disease    606   152\n",
      "18  Tinea Ringworm Candidiasis and other Fungal In...   1300   325\n",
      "19                                    Urticaria Hives    212    53\n",
      "20                                    Vascular Tumors    482   121\n",
      "21                                  Vasculitis Photos    416   105\n",
      "22         Warts Molluscum and other Viral Infections   1086   272\n"
     ]
    }
   ],
   "source": [
    "# credits: https://github.com/yuliyabohdan/Skin-diseases-classification-Dermnet-/blob/main/skin_diseases_clas_ResNet50.ipynb\n",
    "\n",
    "DIR = 'dermnet'\n",
    "DIR_TRAIN = f'{DIR}/train/'\n",
    "DIR_TEST = f'{DIR}/test/'\n",
    "\n",
    "classes = os.listdir(DIR_TRAIN)\n",
    "print(f'Total classes: {len(classes)}')\n",
    "\n",
    "# total train and test images\n",
    "train_count = 0\n",
    "test_count = 0\n",
    "\n",
    "classes_df = []\n",
    "for _class in classes:\n",
    "    class_dict = {}\n",
    "    train_count += len(os.listdir(DIR_TRAIN + _class))\n",
    "    test_count += len(os.listdir(DIR_TEST + _class))\n",
    "    class_dict.update({'Class': _class, \n",
    "                       'Train': len(os.listdir(DIR_TRAIN + _class)), \n",
    "                       'Test': len(os.listdir(DIR_TEST + _class)) })\n",
    "    classes_df.append(class_dict)\n",
    "\n",
    "print(f'Total num train images: {train_count}')\n",
    "print(f'Total num test images: {test_count}')\n",
    "print(pd.DataFrame(classes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd1f6f2f-b8b5-49fb-b964-7f29ab70e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acne and Rosacea Photos': 0,\n",
       " 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions': 1,\n",
       " 'Atopic Dermatitis Photos': 2,\n",
       " 'Bullous Disease Photos': 3,\n",
       " 'Cellulitis Impetigo and other Bacterial Infections': 4,\n",
       " 'Eczema Photos': 5,\n",
       " 'Exanthems and Drug Eruptions': 6,\n",
       " 'Hair Loss Photos Alopecia and other Hair Diseases': 7,\n",
       " 'Herpes HPV and other STDs Photos': 8,\n",
       " 'Light Diseases and Disorders of Pigmentation': 9,\n",
       " 'Lupus and other Connective Tissue diseases': 10,\n",
       " 'Melanoma Skin Cancer Nevi and Moles': 11,\n",
       " 'Nail Fungus and other Nail Disease': 12,\n",
       " 'Poison Ivy Photos and other Contact Dermatitis': 13,\n",
       " 'Psoriasis pictures Lichen Planus and related diseases': 14,\n",
       " 'Scabies Lyme Disease and other Infestations and Bites': 15,\n",
       " 'Seborrheic Keratoses and other Benign Tumors': 16,\n",
       " 'Systemic Disease': 17,\n",
       " 'Tinea Ringworm Candidiasis and other Fungal Infections': 18,\n",
       " 'Urticaria Hives': 19,\n",
       " 'Vascular Tumors': 20,\n",
       " 'Vasculitis Photos': 21,\n",
       " 'Warts Molluscum and other Viral Infections': 22}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map class labels to integer index\n",
    "\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(DIR_TRAIN + _class):\n",
    "        train_imgs.append(f'{DIR_TRAIN}{_class}/{img}')\n",
    "    \n",
    "    for img in os.listdir(DIR_TEST + _class):\n",
    "        test_imgs.append(f'{DIR_TEST}{_class}/{img}')\n",
    "\n",
    "classToInt = {classes[i]: i for i in range(len(classes))}\n",
    "intToClass = dict(map(reversed, classToInt.items()))\n",
    "classToInt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e2800-07ab-4767-a5dd-dc9c8df7e36d",
   "metadata": {},
   "source": [
    "# Data Split/Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caaf5173-414d-42be-bf1b-1232934451d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = DIR_TRAIN, transform=transforms.Compose([\n",
    "    transforms.RandomRotation([-8, +8]),                                           # if augmentation\n",
    "    transforms.ColorJitter(brightness=0, contrast=0.4, saturation=0, hue=0),      # if augmentation\n",
    "    transforms.RandomHorizontalFlip(),                                            # if augmentation\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))\n",
    "test_dataset = ImageFolder(root = DIR_TEST, transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e477d24-6b26-4399-8d1c-740b258b1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.5 * len(test_dataset))\n",
    "valid_size = len(test_dataset) - test_size\n",
    "valid_dataset, test_dataset = torch.utils.data.random_split(test_dataset, \n",
    "                                                            [valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159f120-456e-440d-b49c-34981e4fb946",
   "metadata": {},
   "source": [
    "# Train/Val Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9580d1e6-e22f-4f95-8a0a-3e4fb9948ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "dataloaders_dict['val'] = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a6e65-be27-435e-8838-8abcdb4eb42a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ecf8668-ae95-425a-86fb-41d2dc1118e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:               \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                #update_bn_stats(model=model, data_loader=dataloaders[phase])  # if update_bn_stats\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                      # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "               # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "   \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2e3726-0651-4508-935a-7dd3d45115bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f\"Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}\")    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c48bc1c-c03b-4131-93bd-9028b30873d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y - find the img from class x labelled as class y \n",
    "def test(model, dl, x, y, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    images_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images_list.append(images.cpu().numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "    \n",
    "    for n in range(60):\n",
    "        for i in range(32):\n",
    "            if (true_labels[n][i] == x)  & (predictions[n][i] == y):\n",
    "                #inv_tensor = inv_normalize(image_list[n][i]])\n",
    "                plt.imshow(np.transpose(images_list[n][i], (1, 2, 0)))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28f8998-757b-48cd-9d27-b11c2433632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 100\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 23, bias=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db7995-9435-4cdb-9595-6a572cf8b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 2.1875 Acc: 0.3517\n",
      "val Loss: 1.8816 Acc: 0.4383\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 1.7020 Acc: 0.4938\n",
      "val Loss: 1.6336 Acc: 0.5052\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 1.4062 Acc: 0.5709\n",
      "val Loss: 1.5291 Acc: 0.5457\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 1.1580 Acc: 0.6450\n",
      "val Loss: 1.4982 Acc: 0.5686\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.9467 Acc: 0.7057\n",
      "val Loss: 1.4336 Acc: 0.5991\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.7651 Acc: 0.7627\n",
      "val Loss: 1.4701 Acc: 0.5936\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 0.7965\n",
      "val Loss: 1.4614 Acc: 0.6071\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.5195 Acc: 0.8334\n",
      "val Loss: 1.5462 Acc: 0.6106\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.4527 Acc: 0.8544\n",
      "val Loss: 1.5381 Acc: 0.5986\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.3964 Acc: 0.8710\n",
      "val Loss: 1.4657 Acc: 0.6261\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.3465 Acc: 0.8846\n",
      "val Loss: 1.5840 Acc: 0.6201\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.3202 Acc: 0.8919\n",
      "val Loss: 1.5626 Acc: 0.6161\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.2861 Acc: 0.9081\n",
      "val Loss: 1.6955 Acc: 0.6186\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.2901 Acc: 0.9008\n",
      "val Loss: 1.6936 Acc: 0.6091\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.2596 Acc: 0.9123\n",
      "val Loss: 1.7495 Acc: 0.6126\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.2642 Acc: 0.9070\n",
      "val Loss: 1.8439 Acc: 0.5986\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.2542 Acc: 0.9123\n",
      "val Loss: 1.7876 Acc: 0.6246\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.2275 Acc: 0.9227\n",
      "val Loss: 1.7418 Acc: 0.6011\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.2209 Acc: 0.9241\n",
      "val Loss: 1.7301 Acc: 0.6306\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.1996 Acc: 0.9307\n",
      "val Loss: 1.7106 Acc: 0.6385\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.2104 Acc: 0.9250\n",
      "val Loss: 1.7784 Acc: 0.6345\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.2105 Acc: 0.9259\n",
      "val Loss: 1.6934 Acc: 0.6490\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.1836 Acc: 0.9344\n",
      "val Loss: 1.8595 Acc: 0.6370\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.1966 Acc: 0.9286\n",
      "val Loss: 1.7886 Acc: 0.6495\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.1558 Acc: 0.9443\n",
      "val Loss: 1.7580 Acc: 0.6266\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.1888 Acc: 0.9300\n",
      "val Loss: 1.9113 Acc: 0.6166\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.1912 Acc: 0.9293\n",
      "val Loss: 1.7880 Acc: 0.6440\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.1675 Acc: 0.9367\n",
      "val Loss: 1.9157 Acc: 0.6301\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.1509 Acc: 0.9430\n",
      "val Loss: 1.7397 Acc: 0.6530\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.1570 Acc: 0.9402\n",
      "val Loss: 1.8436 Acc: 0.6375\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.1364 Acc: 0.9478\n",
      "val Loss: 1.8778 Acc: 0.6291\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.1566 Acc: 0.9392\n",
      "val Loss: 1.9086 Acc: 0.6296\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.1631 Acc: 0.9371\n",
      "val Loss: 1.9383 Acc: 0.6301\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.1688 Acc: 0.9350\n",
      "val Loss: 1.9085 Acc: 0.6390\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.1390 Acc: 0.9470\n",
      "val Loss: 1.9295 Acc: 0.6345\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.1318 Acc: 0.9488\n",
      "val Loss: 2.0149 Acc: 0.6191\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9458\n",
      "val Loss: 1.9906 Acc: 0.6236\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.1477 Acc: 0.9434\n",
      "val Loss: 1.9646 Acc: 0.6281\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.1327 Acc: 0.9452\n",
      "val Loss: 1.9296 Acc: 0.6241\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.1356 Acc: 0.9468\n",
      "val Loss: 1.9185 Acc: 0.6256\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.1373 Acc: 0.9471\n",
      "val Loss: 1.9687 Acc: 0.6291\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.1434 Acc: 0.9439\n",
      "val Loss: 2.0075 Acc: 0.6221\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.1154 Acc: 0.9541\n",
      "val Loss: 2.0078 Acc: 0.6306\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.1238 Acc: 0.9499\n",
      "val Loss: 1.9595 Acc: 0.6276\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9481\n",
      "val Loss: 1.9637 Acc: 0.6380\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.1233 Acc: 0.9507\n",
      "val Loss: 2.1218 Acc: 0.6296\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.1185 Acc: 0.9516\n",
      "val Loss: 1.9703 Acc: 0.6420\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.1274 Acc: 0.9488\n",
      "val Loss: 2.0706 Acc: 0.6086\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.1057 Acc: 0.9529\n",
      "val Loss: 2.0877 Acc: 0.6226\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.1143 Acc: 0.9546\n",
      "val Loss: 2.1280 Acc: 0.6206\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.1290 Acc: 0.9480\n",
      "val Loss: 2.0723 Acc: 0.6251\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.1273 Acc: 0.9501\n",
      "val Loss: 1.9268 Acc: 0.6415\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.1201 Acc: 0.9506\n",
      "val Loss: 2.0768 Acc: 0.6291\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.1040 Acc: 0.9565\n",
      "val Loss: 2.0867 Acc: 0.6266\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.1020 Acc: 0.9560\n",
      "val Loss: 2.0615 Acc: 0.6335\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9420\n",
      "val Loss: 2.0648 Acc: 0.6231\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.1036 Acc: 0.9549\n",
      "val Loss: 1.9480 Acc: 0.6340\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.1121 Acc: 0.9543\n",
      "val Loss: 1.9887 Acc: 0.6365\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.0815 Acc: 0.9645\n",
      "val Loss: 2.0859 Acc: 0.6380\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.1098 Acc: 0.9550\n",
      "val Loss: 2.1268 Acc: 0.6281\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.1124 Acc: 0.9515\n",
      "val Loss: 2.0314 Acc: 0.6355\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.1060 Acc: 0.9562\n",
      "val Loss: 1.9807 Acc: 0.6246\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.0839 Acc: 0.9639\n",
      "val Loss: 2.0614 Acc: 0.6375\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.0928 Acc: 0.9594\n",
      "val Loss: 2.0808 Acc: 0.6206\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.1050 Acc: 0.9549\n",
      "val Loss: 2.1652 Acc: 0.6151\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.0981 Acc: 0.9570\n",
      "val Loss: 2.2246 Acc: 0.6191\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.1089 Acc: 0.9544\n",
      "val Loss: 2.0777 Acc: 0.6271\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9547\n",
      "val Loss: 2.1197 Acc: 0.6166\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.0927 Acc: 0.9590\n",
      "val Loss: 2.0923 Acc: 0.6266\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9567\n",
      "val Loss: 2.2204 Acc: 0.6241\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.1032 Acc: 0.9548\n",
      "val Loss: 2.1700 Acc: 0.6291\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.0966 Acc: 0.9578\n",
      "val Loss: 2.2530 Acc: 0.6206\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.1020 Acc: 0.9552\n",
      "val Loss: 2.2712 Acc: 0.6216\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.0901 Acc: 0.9602\n",
      "val Loss: 2.1198 Acc: 0.6266\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.0742 Acc: 0.9647\n",
      "val Loss: 2.1590 Acc: 0.6221\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.1000 Acc: 0.9561\n",
      "val Loss: 2.1118 Acc: 0.6360\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.0916 Acc: 0.9595\n",
      "val Loss: 2.1324 Acc: 0.6291\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.0905 Acc: 0.9583\n",
      "val Loss: 2.1779 Acc: 0.6156\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.1066 Acc: 0.9543\n",
      "val Loss: 2.1437 Acc: 0.6246\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.0767 Acc: 0.9637\n",
      "val Loss: 2.2372 Acc: 0.6256\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.0694 Acc: 0.9652\n",
      "val Loss: 2.1344 Acc: 0.6345\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.0826 Acc: 0.9625\n",
      "val Loss: 2.3611 Acc: 0.6146\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.1071 Acc: 0.9542\n",
      "val Loss: 2.1079 Acc: 0.6141\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ece5f9-f83a-4e8a-8bda-90a9c2d090a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
