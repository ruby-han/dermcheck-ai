{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd076c0-dd88-43f1-819f-bcd83e8b53eb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af3ecf0-9659-4e60-92ea-e70978f75ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install opencv-python-headless\n",
    "# %pip install scikit-image\n",
    "# %pip install basic-image-eda\n",
    "# %pip install seaborn\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bd4a1d-1ead-4a16-9df9-853b1388aa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mp_image\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec757f59-bfeb-4fd5-a3a8-52a79aac39fb",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6a74e9-a024-45c6-ac57-6bc1460956eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 23\n",
      "Total num train images: 15557\n",
      "Total num test images: 4002\n",
      "                                                Class  Train  Test\n",
      "0                    Herpes HPV and other STDs Photos    405   102\n",
      "1          Lupus and other Connective Tissue diseases    420   105\n",
      "2                 Melanoma Skin Cancer Nevi and Moles    463   116\n",
      "3                                     Urticaria Hives    212    53\n",
      "4                                     Vascular Tumors    482   121\n",
      "5                                    Systemic Disease    606   152\n",
      "6                  Nail Fungus and other Nail Disease   1040   261\n",
      "7   Psoriasis pictures Lichen Planus and related d...   1405   352\n",
      "8   Cellulitis Impetigo and other Bacterial Infect...    288    73\n",
      "9   Tinea Ringworm Candidiasis and other Fungal In...   1300   325\n",
      "10  Scabies Lyme Disease and other Infestations an...    431   108\n",
      "11  Hair Loss Photos Alopecia and other Hair Diseases    239    60\n",
      "12         Warts Molluscum and other Viral Infections   1086   272\n",
      "13                                      Eczema Photos   1235   309\n",
      "14  Actinic Keratosis Basal Cell Carcinoma and oth...   1149   288\n",
      "15                                  Vasculitis Photos    416   105\n",
      "16     Poison Ivy Photos and other Contact Dermatitis    260    65\n",
      "17                       Exanthems and Drug Eruptions    404   101\n",
      "18                           Atopic Dermatitis Photos    489   123\n",
      "19       Light Diseases and Disorders of Pigmentation    568   143\n",
      "20                            Acne and Rosacea Photos    840   312\n",
      "21       Seborrheic Keratoses and other Benign Tumors   1371   343\n",
      "22                             Bullous Disease Photos    448   113\n"
     ]
    }
   ],
   "source": [
    "# credits: https://github.com/yuliyabohdan/Skin-diseases-classification-Dermnet-/blob/main/skin_diseases_clas_ResNet50.ipynb\n",
    "\n",
    "DIR = 'dermnet'\n",
    "DIR_TRAIN = f'{DIR}/train/'\n",
    "DIR_TEST = f'{DIR}/test/'\n",
    "\n",
    "classes = os.listdir(DIR_TRAIN)\n",
    "print(f'Total classes: {len(classes)}')\n",
    "\n",
    "# total train and test images\n",
    "train_count = 0\n",
    "test_count = 0\n",
    "\n",
    "classes_df = []\n",
    "for _class in classes:\n",
    "    class_dict = {}\n",
    "    train_count += len(os.listdir(DIR_TRAIN + _class))\n",
    "    test_count += len(os.listdir(DIR_TEST + _class))\n",
    "    class_dict.update({'Class': _class, \n",
    "                       'Train': len(os.listdir(DIR_TRAIN + _class)), \n",
    "                       'Test': len(os.listdir(DIR_TEST + _class)) })\n",
    "    classes_df.append(class_dict)\n",
    "\n",
    "print(f'Total num train images: {train_count}')\n",
    "print(f'Total num test images: {test_count}')\n",
    "print(pd.DataFrame(classes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd1f6f2f-b8b5-49fb-b964-7f29ab70e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Herpes HPV and other STDs Photos': 0,\n",
       " 'Lupus and other Connective Tissue diseases': 1,\n",
       " 'Melanoma Skin Cancer Nevi and Moles': 2,\n",
       " 'Urticaria Hives': 3,\n",
       " 'Vascular Tumors': 4,\n",
       " 'Systemic Disease': 5,\n",
       " 'Nail Fungus and other Nail Disease': 6,\n",
       " 'Psoriasis pictures Lichen Planus and related diseases': 7,\n",
       " 'Cellulitis Impetigo and other Bacterial Infections': 8,\n",
       " 'Tinea Ringworm Candidiasis and other Fungal Infections': 9,\n",
       " 'Scabies Lyme Disease and other Infestations and Bites': 10,\n",
       " 'Hair Loss Photos Alopecia and other Hair Diseases': 11,\n",
       " 'Warts Molluscum and other Viral Infections': 12,\n",
       " 'Eczema Photos': 13,\n",
       " 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions': 14,\n",
       " 'Vasculitis Photos': 15,\n",
       " 'Poison Ivy Photos and other Contact Dermatitis': 16,\n",
       " 'Exanthems and Drug Eruptions': 17,\n",
       " 'Atopic Dermatitis Photos': 18,\n",
       " 'Light Diseases and Disorders of Pigmentation': 19,\n",
       " 'Acne and Rosacea Photos': 20,\n",
       " 'Seborrheic Keratoses and other Benign Tumors': 21,\n",
       " 'Bullous Disease Photos': 22}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map class labels to integer index\n",
    "\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(DIR_TRAIN + _class):\n",
    "        train_imgs.append(f'{DIR_TRAIN}{_class}/{img}')\n",
    "    \n",
    "    for img in os.listdir(DIR_TEST + _class):\n",
    "        test_imgs.append(f'{DIR_TEST}{_class}/{img}')\n",
    "\n",
    "classToInt = {classes[i]: i for i in range(len(classes))}\n",
    "intToClass = dict(map(reversed, classToInt.items()))\n",
    "classToInt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e2800-07ab-4767-a5dd-dc9c8df7e36d",
   "metadata": {},
   "source": [
    "# Data Split/Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caaf5173-414d-42be-bf1b-1232934451d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = DIR_TRAIN, transform=transforms.Compose([\n",
    "    transforms.RandomRotation([-8, +8]),                                           # if augmentation\n",
    "    transforms.ColorJitter(brightness=0, contrast=0.4, saturation=0, hue=0),      # if augmentation\n",
    "    transforms.RandomHorizontalFlip(),                                            # if augmentation\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))\n",
    "test_dataset = ImageFolder(root = DIR_TEST, transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e477d24-6b26-4399-8d1c-740b258b1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.5 * len(test_dataset))\n",
    "valid_size = len(test_dataset) - test_size\n",
    "valid_dataset, test_dataset = torch.utils.data.random_split(test_dataset, \n",
    "                                                            [valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159f120-456e-440d-b49c-34981e4fb946",
   "metadata": {},
   "source": [
    "# Train/Val Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9580d1e6-e22f-4f95-8a0a-3e4fb9948ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "dataloaders_dict['val'] = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a6e65-be27-435e-8838-8abcdb4eb42a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ecf8668-ae95-425a-86fb-41d2dc1118e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:               \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                #update_bn_stats(model=model, data_loader=dataloaders[phase])  # if update_bn_stats\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                      # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "               # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "   \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2e3726-0651-4508-935a-7dd3d45115bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f\"Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}\")    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c48bc1c-c03b-4131-93bd-9028b30873d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y - find the img from class x labelled as class y \n",
    "def test(model, dl, x, y, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    images_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images_list.append(images.cpu().numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "    \n",
    "    for n in range(60):\n",
    "        for i in range(32):\n",
    "            if (true_labels[n][i] == x)  & (predictions[n][i] == y):\n",
    "                #inv_tensor = inv_normalize(image_list[n][i]])\n",
    "                plt.imshow(np.transpose(images_list[n][i], (1, 2, 0)))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28f8998-757b-48cd-9d27-b11c2433632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 100\n",
    "\n",
    "model = models.resnet50(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, 23, bias=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001\n",
    ")\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db7995-9435-4cdb-9595-6a572cf8b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 2.3664 Acc: 0.3048\n",
      "val Loss: 1.9634 Acc: 0.4233\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 1.7468 Acc: 0.4813\n",
      "val Loss: 1.6473 Acc: 0.5097\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 1.3629 Acc: 0.5912\n",
      "val Loss: 1.4972 Acc: 0.5467\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 1.0588 Acc: 0.6760\n",
      "val Loss: 1.4109 Acc: 0.5907\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.7884 Acc: 0.7581\n",
      "val Loss: 1.3815 Acc: 0.6072\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.5833 Acc: 0.8198\n",
      "val Loss: 1.4147 Acc: 0.6202\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.4586 Acc: 0.8567\n",
      "val Loss: 1.4312 Acc: 0.6312\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.3670 Acc: 0.8823\n",
      "val Loss: 1.4947 Acc: 0.6147\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.2912 Acc: 0.9038\n",
      "val Loss: 1.5187 Acc: 0.6252\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.2514 Acc: 0.9125\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ece5f9-f83a-4e8a-8bda-90a9c2d090a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
