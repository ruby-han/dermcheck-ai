{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd076c0-dd88-43f1-819f-bcd83e8b53eb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af3ecf0-9659-4e60-92ea-e70978f75ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install opencv-python-headless\n",
    "# %pip install scikit-image\n",
    "# %pip install basic-image-eda\n",
    "# %pip install seaborn\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bd4a1d-1ead-4a16-9df9-853b1388aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mp_image\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec757f59-bfeb-4fd5-a3a8-52a79aac39fb",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6a74e9-a024-45c6-ac57-6bc1460956eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 23\n",
      "Total num train images: 15557\n",
      "Total num test images: 4003\n",
      "                                                Class  Train  Test\n",
      "0                             Acne and Rosacea Photos    840   313\n",
      "1   Actinic Keratosis Basal Cell Carcinoma and oth...   1149   288\n",
      "2                            Atopic Dermatitis Photos    489   123\n",
      "3                              Bullous Disease Photos    448   113\n",
      "4   Cellulitis Impetigo and other Bacterial Infect...    288    73\n",
      "5                                       Eczema Photos   1235   309\n",
      "6                        Exanthems and Drug Eruptions    404   101\n",
      "7   Hair Loss Photos Alopecia and other Hair Diseases    239    60\n",
      "8                    Herpes HPV and other STDs Photos    405   102\n",
      "9        Light Diseases and Disorders of Pigmentation    568   143\n",
      "10         Lupus and other Connective Tissue diseases    420   105\n",
      "11                Melanoma Skin Cancer Nevi and Moles    463   116\n",
      "12                 Nail Fungus and other Nail Disease   1040   261\n",
      "13     Poison Ivy Photos and other Contact Dermatitis    260    65\n",
      "14  Psoriasis pictures Lichen Planus and related d...   1405   352\n",
      "15  Scabies Lyme Disease and other Infestations an...    431   108\n",
      "16       Seborrheic Keratoses and other Benign Tumors   1371   343\n",
      "17                                   Systemic Disease    606   152\n",
      "18  Tinea Ringworm Candidiasis and other Fungal In...   1300   325\n",
      "19                                    Urticaria Hives    212    53\n",
      "20                                    Vascular Tumors    482   121\n",
      "21                                  Vasculitis Photos    416   105\n",
      "22         Warts Molluscum and other Viral Infections   1086   272\n"
     ]
    }
   ],
   "source": [
    "# credits: https://github.com/yuliyabohdan/Skin-diseases-classification-Dermnet-/blob/main/skin_diseases_clas_ResNet50.ipynb\n",
    "\n",
    "DIR = 'dermnet'\n",
    "DIR_TRAIN = f'{DIR}/train/'\n",
    "DIR_TEST = f'{DIR}/test/'\n",
    "\n",
    "classes = os.listdir(DIR_TRAIN)\n",
    "print(f'Total classes: {len(classes)}')\n",
    "\n",
    "# total train and test images\n",
    "train_count = 0\n",
    "test_count = 0\n",
    "\n",
    "classes_df = []\n",
    "for _class in classes:\n",
    "    class_dict = {}\n",
    "    train_count += len(os.listdir(DIR_TRAIN + _class))\n",
    "    test_count += len(os.listdir(DIR_TEST + _class))\n",
    "    class_dict.update({'Class': _class, \n",
    "                       'Train': len(os.listdir(DIR_TRAIN + _class)), \n",
    "                       'Test': len(os.listdir(DIR_TEST + _class)) })\n",
    "    classes_df.append(class_dict)\n",
    "\n",
    "print(f'Total num train images: {train_count}')\n",
    "print(f'Total num test images: {test_count}')\n",
    "print(pd.DataFrame(classes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd1f6f2f-b8b5-49fb-b964-7f29ab70e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acne and Rosacea Photos': 0,\n",
       " 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions': 1,\n",
       " 'Atopic Dermatitis Photos': 2,\n",
       " 'Bullous Disease Photos': 3,\n",
       " 'Cellulitis Impetigo and other Bacterial Infections': 4,\n",
       " 'Eczema Photos': 5,\n",
       " 'Exanthems and Drug Eruptions': 6,\n",
       " 'Hair Loss Photos Alopecia and other Hair Diseases': 7,\n",
       " 'Herpes HPV and other STDs Photos': 8,\n",
       " 'Light Diseases and Disorders of Pigmentation': 9,\n",
       " 'Lupus and other Connective Tissue diseases': 10,\n",
       " 'Melanoma Skin Cancer Nevi and Moles': 11,\n",
       " 'Nail Fungus and other Nail Disease': 12,\n",
       " 'Poison Ivy Photos and other Contact Dermatitis': 13,\n",
       " 'Psoriasis pictures Lichen Planus and related diseases': 14,\n",
       " 'Scabies Lyme Disease and other Infestations and Bites': 15,\n",
       " 'Seborrheic Keratoses and other Benign Tumors': 16,\n",
       " 'Systemic Disease': 17,\n",
       " 'Tinea Ringworm Candidiasis and other Fungal Infections': 18,\n",
       " 'Urticaria Hives': 19,\n",
       " 'Vascular Tumors': 20,\n",
       " 'Vasculitis Photos': 21,\n",
       " 'Warts Molluscum and other Viral Infections': 22}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map class labels to integer index\n",
    "\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(DIR_TRAIN + _class):\n",
    "        train_imgs.append(f'{DIR_TRAIN}{_class}/{img}')\n",
    "    \n",
    "    for img in os.listdir(DIR_TEST + _class):\n",
    "        test_imgs.append(f'{DIR_TEST}{_class}/{img}')\n",
    "\n",
    "classToInt = {classes[i]: i for i in range(len(classes))}\n",
    "intToClass = dict(map(reversed, classToInt.items()))\n",
    "classToInt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e2800-07ab-4767-a5dd-dc9c8df7e36d",
   "metadata": {},
   "source": [
    "# Data Split/Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caaf5173-414d-42be-bf1b-1232934451d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = DIR_TRAIN, transform=transforms.Compose([\n",
    "    transforms.RandomRotation([-8, +8]),                                           # if augmentation\n",
    "    transforms.ColorJitter(brightness=0, contrast=0.4, saturation=0, hue=0),      # if augmentation\n",
    "    transforms.RandomHorizontalFlip(),                                            # if augmentation\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))\n",
    "test_dataset = ImageFolder(root = DIR_TEST, transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.541, 0.414, 0.382], std=[0.256, 0.215, 0.209])\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e477d24-6b26-4399-8d1c-740b258b1a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.5 * len(test_dataset))\n",
    "valid_size = len(test_dataset) - test_size\n",
    "valid_dataset, test_dataset = torch.utils.data.random_split(test_dataset, \n",
    "                                                            [valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159f120-456e-440d-b49c-34981e4fb946",
   "metadata": {},
   "source": [
    "# Train/Val Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9580d1e6-e22f-4f95-8a0a-3e4fb9948ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "dataloaders_dict['val'] = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a6e65-be27-435e-8838-8abcdb4eb42a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ecf8668-ae95-425a-86fb-41d2dc1118e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:               \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                #update_bn_stats(model=model, data_loader=dataloaders[phase])  # if update_bn_stats\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                      # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "               # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "   \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2e3726-0651-4508-935a-7dd3d45115bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f\"Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}\")    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c48bc1c-c03b-4131-93bd-9028b30873d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y - find the img from class x labelled as class y \n",
    "def test(model, dl, x, y, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    images_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images_list.append(images.cpu().numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "    \n",
    "    for n in range(60):\n",
    "        for i in range(32):\n",
    "            if (true_labels[n][i] == x)  & (predictions[n][i] == y):\n",
    "                #inv_tensor = inv_normalize(image_list[n][i]])\n",
    "                plt.imshow(np.transpose(images_list[n][i], (1, 2, 0)))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a28f8998-757b-48cd-9d27-b11c2433632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 10 #100\n",
    "\n",
    "model = models.resnet50(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, 23, bias=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001\n",
    ")\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3db7995-9435-4cdb-9595-6a572cf8b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 2.3684 Acc: 0.3049\n",
      "val Loss: 1.9935 Acc: 0.4194\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.7505 Acc: 0.4797\n",
      "val Loss: 1.7146 Acc: 0.4973\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.3741 Acc: 0.5851\n",
      "val Loss: 1.5367 Acc: 0.5497\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.0601 Acc: 0.6794\n",
      "val Loss: 1.4431 Acc: 0.5796\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.8046 Acc: 0.7507\n",
      "val Loss: 1.4165 Acc: 0.5956\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.5974 Acc: 0.8158\n",
      "val Loss: 1.3761 Acc: 0.6246\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.4565 Acc: 0.8583\n",
      "val Loss: 1.4458 Acc: 0.6126\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3558 Acc: 0.8855\n",
      "val Loss: 1.4925 Acc: 0.6176\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.2910 Acc: 0.9054\n",
      "val Loss: 1.5394 Acc: 0.6246\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2602 Acc: 0.9152\n",
      "val Loss: 1.5904 Acc: 0.6261\n",
      "\n",
      "Training complete in 27m 31s\n",
      "Best val Acc: 0.626061\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ece5f9-f83a-4e8a-8bda-90a9c2d090a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
