{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB6QjlVmr01i"
   },
   "source": [
    "# Modeling - First Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVEzW45qsn4t"
   },
   "source": [
    "### Installs, Packages, Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUgahMpfsKKF",
    "outputId": "2888a465-c4a0-4425-ae4f-dd9b9e0694c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: efficientnet_pytorch in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from efficientnet_pytorch) (1.10.0)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torch->efficientnet_pytorch) (4.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (1.10.0)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from torch) (4.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hGcQYrTsrhNM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# python libraties\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "from itertools import combinations, product\n",
    "\n",
    "# import imblearn\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import ipywidgets\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# google drive\n",
    "# from google.colab import drive # Connect colab to google drive\n",
    "\n",
    "# custom modeling libraries\n",
    "from build_model2 import initialize_model, load_split_data, build_loader, evaluate, train_model, model_scores, eval_model, add_results\n",
    "\n",
    "# other\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import build_model2\n",
    "importlib.reload(build_model2)\n",
    "\n",
    "from build_model2 import initialize_model, load_split_data, build_loader, evaluate, train_model, model_scores, eval_model, add_results\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# print(mpl.get_cachedir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_search = [5, 10, 15, 20]\n",
    "optim_search = ['SGD', 'Adam', 'AdamW']\n",
    "model_search = ['resnet', 'vgg', 'efficientnet']\n",
    "prods = list(product(epoch_search, optim_search, model_search))\n",
    "\n",
    "es = pd.Series(list(zip(*prods))[0], name = 'epochs', dtype = 'int')\n",
    "optims = pd.Series(list(zip(*prods))[1], name = 'optimizer')\n",
    "mods = pd.Series(list(zip(*prods))[2], name = 'pretrained_model')\n",
    "\n",
    "g_search = pd.concat([es, optims, mods], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "576JOVVyzMBp"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Type: Tesla T4\n",
      "GPU Count: 1\n"
     ]
    }
   ],
   "source": [
    "model_dict = {'pretrained_model': None, \n",
    "              'epochs': None, # NEEDS UPDATE\n",
    "              'home_directory': '/home/ec2-user/SageMaker/teledermatologyAI_capstone',\n",
    "              'mod_directory': '/home/ec2-user/SageMaker/teledermatologyAI_capstone/model/gridsearch2',\n",
    "              'csv_name': 'full_data_rename',\n",
    "              'split': 'split_3',\n",
    "              'cl': 'label_0',\n",
    "              'dev_state': False,\n",
    "              'dev_sample': 15000,\n",
    "              'seed': 99,\n",
    "              'lr': .0035,                  # from prior gridsearch\n",
    "              'batch_size':64,\n",
    "              'num_workers':24,\n",
    "              'transform':3,\n",
    "              'results_file':'gridsearch_results',\n",
    "              'model':None, # NEEDS UPDATE\n",
    "              'device': torch.device('cuda:0'), # NEEDS UPDATE\n",
    "              'optimizer': None, # NEEDS UPDATE\n",
    "              'criterion': None, # NEEDS UPDATE\n",
    "              'tuned_model_name': None, # NEEDS UPDATE\n",
    "              'show_val_cm': False,\n",
    "             }\n",
    "\n",
    "np.random.seed(model_dict['seed'])\n",
    "torch.cuda.manual_seed(model_dict['seed'])\n",
    "\n",
    "# Check GPU\n",
    "print('GPU Type:', torch.cuda.get_device_name())\n",
    "print('GPU Count:', torch.cuda.device_count())\n",
    "\n",
    "HOME = model_dict['home_directory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/teledermatologyAI_capstone\n"
     ]
    }
   ],
   "source": [
    "cd $HOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, train, test, val = load_split_data(directory = model_dict['home_directory'],\n",
    "                                         csv_name = model_dict['csv_name'], \n",
    "                                         data_split = model_dict['split'], \n",
    "                                         label = model_dict['cl'],\n",
    "                                         mode = 'all',\n",
    "                                         dev_state = model_dict['dev_state'], \n",
    "                                         dev_sample = model_dict['dev_sample'], \n",
    "                                         seed = model_dict['seed']\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label dictionary for evaluation\n",
    "labels_idx = np.sort(data.label_idx.unique())\n",
    "label_map = data[['label', 'label_idx']].drop_duplicates().sort_values('label_idx')\n",
    "label_dict = dict(zip(label_map.label_idx, label_map['label']))\n",
    "model_dict['label_dict'] = label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TaPtH1nqVCm"
   },
   "source": [
    "## In for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_search = g_search[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "Starting Training efficientnet_5e_SGD_GS2\n",
      "[epoch 1], [iter 100 of 4500],[train loss 1.57537], [train acc 0.25333]\n",
      "[epoch 1], [iter 200 of 4500],[train loss 1.55926], [train acc 0.28167]\n",
      "[epoch 1], [iter 300 of 4500],[train loss 1.53391], [train acc 0.30444]\n",
      "[epoch 1], [iter 400 of 4500],[train loss 1.51185], [train acc 0.32083]\n",
      "[epoch 1], [iter 500 of 4500],[train loss 1.49566], [train acc 0.33800]\n",
      "[epoch 1], [iter 600 of 4500],[train loss 1.48120], [train acc 0.34889]\n",
      "[epoch 1], [iter 700 of 4500],[train loss 1.46117], [train acc 0.36000]\n",
      "[epoch 1], [iter 800 of 4500],[train loss 1.44990], [train acc 0.36292]\n",
      "[epoch 1], [iter 900 of 4500],[train loss 1.44659], [train acc 0.36407]\n",
      "[epoch 1], [iter 1000 of 4500],[train loss 1.43496], [train acc 0.36967]\n",
      "[epoch 1], [iter 1100 of 4500],[train loss 1.43112], [train acc 0.37424]\n",
      "[epoch 1], [iter 1200 of 4500],[train loss 1.42509], [train acc 0.38111]\n",
      "[epoch 1], [iter 1300 of 4500],[train loss 1.41470], [train acc 0.38718]\n",
      "[epoch 1], [iter 1400 of 4500],[train loss 1.40444], [train acc 0.39333]\n",
      "[epoch 1], [iter 1500 of 4500],[train loss 1.39979], [train acc 0.39689]\n",
      "[epoch 1], [iter 1600 of 4500],[train loss 1.39522], [train acc 0.40000]\n",
      "[epoch 1], [iter 1700 of 4500],[train loss 1.38661], [train acc 0.40529]\n",
      "[epoch 1], [iter 1800 of 4500],[train loss 1.38226], [train acc 0.40833]\n",
      "[epoch 1], [iter 1900 of 4500],[train loss 1.37971], [train acc 0.41070]\n",
      "[epoch 1], [iter 2000 of 4500],[train loss 1.37174], [train acc 0.41583]\n",
      "[epoch 1], [iter 2100 of 4500],[train loss 1.36692], [train acc 0.41889]\n",
      "[epoch 1], [iter 2200 of 4500],[train loss 1.36024], [train acc 0.42273]\n",
      "[epoch 1], [iter 2300 of 4500],[train loss 1.35658], [train acc 0.42377]\n",
      "[epoch 1], [iter 2400 of 4500],[train loss 1.34869], [train acc 0.42722]\n",
      "[epoch 1], [iter 2500 of 4500],[train loss 1.34322], [train acc 0.42907]\n",
      "[epoch 1], [iter 2600 of 4500],[train loss 1.34222], [train acc 0.43000]\n",
      "[epoch 1], [iter 2700 of 4500],[train loss 1.33717], [train acc 0.43086]\n",
      "[epoch 1], [iter 2800 of 4500],[train loss 1.33639], [train acc 0.43274]\n",
      "[epoch 1], [iter 2900 of 4500],[train loss 1.33253], [train acc 0.43494]\n",
      "[epoch 1], [iter 3000 of 4500],[train loss 1.32877], [train acc 0.43722]\n",
      "[epoch 1], [iter 3100 of 4500],[train loss 1.32814], [train acc 0.43785]\n",
      "[epoch 1], [iter 3200 of 4500],[train loss 1.32541], [train acc 0.43958]\n",
      "[epoch 1], [iter 3300 of 4500],[train loss 1.32159], [train acc 0.44121]\n",
      "[epoch 1], [iter 3400 of 4500],[train loss 1.31773], [train acc 0.44314]\n",
      "[epoch 1], [iter 3500 of 4500],[train loss 1.31384], [train acc 0.44648]\n",
      "[epoch 1], [iter 3600 of 4500],[train loss 1.31231], [train acc 0.44741]\n",
      "[epoch 1], [iter 3700 of 4500],[train loss 1.30947], [train acc 0.44946]\n",
      "[epoch 1], [iter 3800 of 4500],[train loss 1.30646], [train acc 0.45079]\n",
      "[epoch 1], [iter 3900 of 4500],[train loss 1.30585], [train acc 0.45103]\n",
      "[epoch 1], [iter 4000 of 4500],[train loss 1.30302], [train acc 0.45317]\n",
      "[epoch 1], [iter 4100 of 4500],[train loss 1.29918], [train acc 0.45537]\n",
      "[epoch 1], [iter 4200 of 4500],[train loss 1.29688], [train acc 0.45690]\n",
      "[epoch 1], [iter 4300 of 4500],[train loss 1.29352], [train acc 0.45876]\n",
      "[epoch 1], [iter 4400 of 4500],[train loss 1.29050], [train acc 0.46129]\n",
      "[epoch 1], [iter 4500 of 4500],[train loss 1.28806], [train acc 0.46296]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.15316], [val acc 0.55259]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 :\n",
      "*****************************************************\n",
      "Complete in 76m 31s\n",
      "best record: [epoch 1], [val loss 1.15316], [val acc 0.55259]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 of 4500],[train loss 1.20446], [train acc 0.50667]\n",
      "[epoch 2], [iter 200 of 4500],[train loss 1.19031], [train acc 0.52667]\n",
      "[epoch 2], [iter 300 of 4500],[train loss 1.17857], [train acc 0.54333]\n",
      "[epoch 2], [iter 400 of 4500],[train loss 1.17656], [train acc 0.53333]\n",
      "[epoch 2], [iter 500 of 4500],[train loss 1.17771], [train acc 0.52600]\n",
      "[epoch 2], [iter 600 of 4500],[train loss 1.16466], [train acc 0.52889]\n",
      "[epoch 2], [iter 700 of 4500],[train loss 1.17023], [train acc 0.52714]\n",
      "[epoch 2], [iter 800 of 4500],[train loss 1.16810], [train acc 0.52917]\n",
      "[epoch 2], [iter 900 of 4500],[train loss 1.17104], [train acc 0.52963]\n",
      "[epoch 2], [iter 1000 of 4500],[train loss 1.16715], [train acc 0.53567]\n",
      "[epoch 2], [iter 1100 of 4500],[train loss 1.16126], [train acc 0.53727]\n",
      "[epoch 2], [iter 1200 of 4500],[train loss 1.15940], [train acc 0.53639]\n",
      "[epoch 2], [iter 1300 of 4500],[train loss 1.15879], [train acc 0.53872]\n",
      "[epoch 2], [iter 1400 of 4500],[train loss 1.15903], [train acc 0.53905]\n",
      "[epoch 2], [iter 1500 of 4500],[train loss 1.16022], [train acc 0.53822]\n",
      "[epoch 2], [iter 1600 of 4500],[train loss 1.15625], [train acc 0.53854]\n",
      "[epoch 2], [iter 1700 of 4500],[train loss 1.15108], [train acc 0.54196]\n",
      "[epoch 2], [iter 1800 of 4500],[train loss 1.15329], [train acc 0.53981]\n",
      "[epoch 2], [iter 1900 of 4500],[train loss 1.15144], [train acc 0.54175]\n",
      "[epoch 2], [iter 2000 of 4500],[train loss 1.14710], [train acc 0.54350]\n",
      "[epoch 2], [iter 2100 of 4500],[train loss 1.14567], [train acc 0.54476]\n",
      "[epoch 2], [iter 2200 of 4500],[train loss 1.14447], [train acc 0.54545]\n",
      "[epoch 2], [iter 2300 of 4500],[train loss 1.14485], [train acc 0.54536]\n",
      "[epoch 2], [iter 2400 of 4500],[train loss 1.14516], [train acc 0.54583]\n",
      "[epoch 2], [iter 2500 of 4500],[train loss 1.14565], [train acc 0.54627]\n",
      "[epoch 2], [iter 2600 of 4500],[train loss 1.14507], [train acc 0.54551]\n",
      "[epoch 2], [iter 2700 of 4500],[train loss 1.14387], [train acc 0.54531]\n",
      "[epoch 2], [iter 2800 of 4500],[train loss 1.14316], [train acc 0.54726]\n",
      "[epoch 2], [iter 2900 of 4500],[train loss 1.14251], [train acc 0.54759]\n",
      "[epoch 2], [iter 3000 of 4500],[train loss 1.14260], [train acc 0.54756]\n",
      "[epoch 2], [iter 3100 of 4500],[train loss 1.14244], [train acc 0.54817]\n",
      "[epoch 2], [iter 3200 of 4500],[train loss 1.14179], [train acc 0.54865]\n",
      "[epoch 2], [iter 3300 of 4500],[train loss 1.14071], [train acc 0.54919]\n",
      "[epoch 2], [iter 3400 of 4500],[train loss 1.13862], [train acc 0.54931]\n",
      "[epoch 2], [iter 3500 of 4500],[train loss 1.13655], [train acc 0.55095]\n",
      "[epoch 2], [iter 3600 of 4500],[train loss 1.13882], [train acc 0.54954]\n",
      "[epoch 2], [iter 3700 of 4500],[train loss 1.13466], [train acc 0.55171]\n",
      "[epoch 2], [iter 3800 of 4500],[train loss 1.13384], [train acc 0.55140]\n",
      "[epoch 2], [iter 3900 of 4500],[train loss 1.13581], [train acc 0.55034]\n",
      "[epoch 2], [iter 4000 of 4500],[train loss 1.13366], [train acc 0.55117]\n",
      "[epoch 2], [iter 4100 of 4500],[train loss 1.13369], [train acc 0.55098]\n",
      "[epoch 2], [iter 4200 of 4500],[train loss 1.13274], [train acc 0.55048]\n",
      "[epoch 2], [iter 4300 of 4500],[train loss 1.13218], [train acc 0.55070]\n",
      "[epoch 2], [iter 4400 of 4500],[train loss 1.13050], [train acc 0.55197]\n",
      "[epoch 2], [iter 4500 of 4500],[train loss 1.12985], [train acc 0.55193]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.00454], [val acc 0.62222]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 :\n",
      "*****************************************************\n",
      "Complete in 75m 37s\n",
      "best record: [epoch 2], [val loss 1.00454], [val acc 0.62222]\n",
      "*****************************************************\n",
      "[epoch 3], [iter 100 of 4500],[train loss 1.07813], [train acc 0.59000]\n",
      "[epoch 3], [iter 200 of 4500],[train loss 1.07974], [train acc 0.57500]\n",
      "[epoch 3], [iter 300 of 4500],[train loss 1.07885], [train acc 0.56778]\n",
      "[epoch 3], [iter 400 of 4500],[train loss 1.07200], [train acc 0.56750]\n",
      "[epoch 3], [iter 500 of 4500],[train loss 1.06673], [train acc 0.56933]\n",
      "[epoch 3], [iter 600 of 4500],[train loss 1.06170], [train acc 0.57556]\n",
      "[epoch 3], [iter 700 of 4500],[train loss 1.06331], [train acc 0.57476]\n",
      "[epoch 3], [iter 800 of 4500],[train loss 1.06264], [train acc 0.57583]\n",
      "[epoch 3], [iter 900 of 4500],[train loss 1.05708], [train acc 0.58519]\n",
      "[epoch 3], [iter 1000 of 4500],[train loss 1.05949], [train acc 0.58367]\n",
      "[epoch 3], [iter 1100 of 4500],[train loss 1.05498], [train acc 0.58545]\n",
      "[epoch 3], [iter 1200 of 4500],[train loss 1.05670], [train acc 0.58417]\n",
      "[epoch 3], [iter 1300 of 4500],[train loss 1.05539], [train acc 0.58513]\n",
      "[epoch 3], [iter 1400 of 4500],[train loss 1.05383], [train acc 0.58571]\n",
      "[epoch 3], [iter 1500 of 4500],[train loss 1.05619], [train acc 0.58644]\n",
      "[epoch 3], [iter 1600 of 4500],[train loss 1.05177], [train acc 0.58917]\n",
      "[epoch 3], [iter 1700 of 4500],[train loss 1.04935], [train acc 0.59157]\n",
      "[epoch 3], [iter 1800 of 4500],[train loss 1.04470], [train acc 0.59389]\n",
      "[epoch 3], [iter 1900 of 4500],[train loss 1.04466], [train acc 0.59281]\n",
      "[epoch 3], [iter 2000 of 4500],[train loss 1.04534], [train acc 0.59367]\n",
      "[epoch 3], [iter 2100 of 4500],[train loss 1.04493], [train acc 0.59143]\n",
      "[epoch 3], [iter 2200 of 4500],[train loss 1.04511], [train acc 0.59106]\n",
      "[epoch 3], [iter 2300 of 4500],[train loss 1.04385], [train acc 0.59087]\n",
      "[epoch 3], [iter 2400 of 4500],[train loss 1.04152], [train acc 0.59222]\n",
      "[epoch 3], [iter 2500 of 4500],[train loss 1.04079], [train acc 0.59240]\n",
      "[epoch 3], [iter 2600 of 4500],[train loss 1.04055], [train acc 0.59231]\n",
      "[epoch 3], [iter 2700 of 4500],[train loss 1.04227], [train acc 0.59296]\n",
      "[epoch 3], [iter 2800 of 4500],[train loss 1.04010], [train acc 0.59357]\n",
      "[epoch 3], [iter 2900 of 4500],[train loss 1.04110], [train acc 0.59310]\n",
      "[epoch 3], [iter 3000 of 4500],[train loss 1.03868], [train acc 0.59433]\n",
      "[epoch 3], [iter 3100 of 4500],[train loss 1.03907], [train acc 0.59462]\n",
      "[epoch 3], [iter 3200 of 4500],[train loss 1.03562], [train acc 0.59688]\n",
      "[epoch 3], [iter 3300 of 4500],[train loss 1.03531], [train acc 0.59747]\n",
      "[epoch 3], [iter 3400 of 4500],[train loss 1.03502], [train acc 0.59706]\n",
      "[epoch 3], [iter 3500 of 4500],[train loss 1.03501], [train acc 0.59705]\n",
      "[epoch 3], [iter 3600 of 4500],[train loss 1.03207], [train acc 0.59806]\n",
      "[epoch 3], [iter 3700 of 4500],[train loss 1.03057], [train acc 0.59856]\n",
      "[epoch 3], [iter 3800 of 4500],[train loss 1.03230], [train acc 0.59772]\n",
      "[epoch 3], [iter 3900 of 4500],[train loss 1.03084], [train acc 0.59829]\n",
      "[epoch 3], [iter 4000 of 4500],[train loss 1.02890], [train acc 0.59917]\n",
      "[epoch 3], [iter 4100 of 4500],[train loss 1.02993], [train acc 0.59837]\n",
      "[epoch 3], [iter 4200 of 4500],[train loss 1.02707], [train acc 0.60008]\n",
      "[epoch 3], [iter 4300 of 4500],[train loss 1.02667], [train acc 0.59953]\n",
      "[epoch 3], [iter 4400 of 4500],[train loss 1.02598], [train acc 0.60015]\n",
      "[epoch 3], [iter 4500 of 4500],[train loss 1.02453], [train acc 0.60074]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.95014], [val acc 0.63333]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 :\n",
      "*****************************************************\n",
      "Complete in 75m 41s\n",
      "best record: [epoch 3], [val loss 0.95014], [val acc 0.63333]\n",
      "*****************************************************\n",
      "[epoch 4], [iter 100 of 4500],[train loss 1.01766], [train acc 0.58333]\n",
      "[epoch 4], [iter 200 of 4500],[train loss 0.98907], [train acc 0.60833]\n",
      "[epoch 4], [iter 300 of 4500],[train loss 0.99552], [train acc 0.61556]\n",
      "[epoch 4], [iter 400 of 4500],[train loss 0.98955], [train acc 0.61917]\n",
      "[epoch 4], [iter 500 of 4500],[train loss 0.99540], [train acc 0.60867]\n",
      "[epoch 4], [iter 600 of 4500],[train loss 0.98700], [train acc 0.61222]\n",
      "[epoch 4], [iter 700 of 4500],[train loss 0.99207], [train acc 0.61429]\n",
      "[epoch 4], [iter 800 of 4500],[train loss 0.97709], [train acc 0.62042]\n",
      "[epoch 4], [iter 900 of 4500],[train loss 0.97947], [train acc 0.61852]\n",
      "[epoch 4], [iter 1000 of 4500],[train loss 0.98526], [train acc 0.61700]\n",
      "[epoch 4], [iter 1100 of 4500],[train loss 0.97912], [train acc 0.62182]\n",
      "[epoch 4], [iter 1200 of 4500],[train loss 0.97691], [train acc 0.62333]\n",
      "[epoch 4], [iter 1300 of 4500],[train loss 0.97339], [train acc 0.62590]\n",
      "[epoch 4], [iter 1400 of 4500],[train loss 0.96896], [train acc 0.62786]\n",
      "[epoch 4], [iter 1500 of 4500],[train loss 0.96836], [train acc 0.62956]\n",
      "[epoch 4], [iter 1600 of 4500],[train loss 0.97082], [train acc 0.62687]\n",
      "[epoch 4], [iter 1700 of 4500],[train loss 0.97152], [train acc 0.62373]\n",
      "[epoch 4], [iter 1800 of 4500],[train loss 0.97042], [train acc 0.62389]\n",
      "[epoch 4], [iter 1900 of 4500],[train loss 0.97429], [train acc 0.62263]\n",
      "[epoch 4], [iter 2000 of 4500],[train loss 0.97414], [train acc 0.62233]\n",
      "[epoch 4], [iter 2100 of 4500],[train loss 0.97452], [train acc 0.62143]\n",
      "[epoch 4], [iter 2200 of 4500],[train loss 0.97506], [train acc 0.62212]\n",
      "[epoch 4], [iter 2300 of 4500],[train loss 0.97414], [train acc 0.62174]\n",
      "[epoch 4], [iter 2400 of 4500],[train loss 0.97458], [train acc 0.62056]\n",
      "[epoch 4], [iter 2500 of 4500],[train loss 0.97237], [train acc 0.62160]\n",
      "[epoch 4], [iter 2600 of 4500],[train loss 0.97115], [train acc 0.62115]\n",
      "[epoch 4], [iter 2700 of 4500],[train loss 0.97108], [train acc 0.62086]\n",
      "[epoch 4], [iter 2800 of 4500],[train loss 0.97109], [train acc 0.62083]\n",
      "[epoch 4], [iter 2900 of 4500],[train loss 0.96947], [train acc 0.62172]\n",
      "[epoch 4], [iter 3000 of 4500],[train loss 0.96875], [train acc 0.62233]\n",
      "[epoch 4], [iter 3100 of 4500],[train loss 0.96869], [train acc 0.62194]\n",
      "[epoch 4], [iter 3200 of 4500],[train loss 0.96767], [train acc 0.62250]\n",
      "[epoch 4], [iter 3300 of 4500],[train loss 0.96734], [train acc 0.62263]\n",
      "[epoch 4], [iter 3400 of 4500],[train loss 0.96845], [train acc 0.62127]\n",
      "[epoch 4], [iter 3500 of 4500],[train loss 0.96781], [train acc 0.62152]\n",
      "[epoch 4], [iter 3600 of 4500],[train loss 0.96652], [train acc 0.62194]\n",
      "[epoch 4], [iter 3700 of 4500],[train loss 0.96774], [train acc 0.62108]\n",
      "[epoch 4], [iter 3800 of 4500],[train loss 0.96652], [train acc 0.62228]\n",
      "[epoch 4], [iter 3900 of 4500],[train loss 0.96512], [train acc 0.62256]\n",
      "[epoch 4], [iter 4000 of 4500],[train loss 0.96436], [train acc 0.62367]\n",
      "[epoch 4], [iter 4100 of 4500],[train loss 0.96545], [train acc 0.62350]\n",
      "[epoch 4], [iter 4200 of 4500],[train loss 0.96510], [train acc 0.62381]\n",
      "[epoch 4], [iter 4300 of 4500],[train loss 0.96424], [train acc 0.62388]\n",
      "[epoch 4], [iter 4400 of 4500],[train loss 0.96380], [train acc 0.62394]\n",
      "[epoch 4], [iter 4500 of 4500],[train loss 0.96299], [train acc 0.62385]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.90440], [val acc 0.64370]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 :\n",
      "*****************************************************\n",
      "Complete in 76m 27s\n",
      "best record: [epoch 4], [val loss 0.90440], [val acc 0.64370]\n",
      "*****************************************************\n",
      "[epoch 5], [iter 100 of 4500],[train loss 0.93108], [train acc 0.61333]\n",
      "[epoch 5], [iter 200 of 4500],[train loss 0.92565], [train acc 0.62500]\n",
      "[epoch 5], [iter 300 of 4500],[train loss 0.89898], [train acc 0.64000]\n",
      "[epoch 5], [iter 400 of 4500],[train loss 0.88755], [train acc 0.64417]\n",
      "[epoch 5], [iter 500 of 4500],[train loss 0.90410], [train acc 0.64333]\n",
      "[epoch 5], [iter 600 of 4500],[train loss 0.90759], [train acc 0.64444]\n",
      "[epoch 5], [iter 700 of 4500],[train loss 0.91919], [train acc 0.64000]\n",
      "[epoch 5], [iter 800 of 4500],[train loss 0.91914], [train acc 0.64167]\n",
      "[epoch 5], [iter 900 of 4500],[train loss 0.92106], [train acc 0.64259]\n",
      "[epoch 5], [iter 1000 of 4500],[train loss 0.92174], [train acc 0.64000]\n",
      "[epoch 5], [iter 1100 of 4500],[train loss 0.91978], [train acc 0.64000]\n",
      "[epoch 5], [iter 1200 of 4500],[train loss 0.91950], [train acc 0.64222]\n",
      "[epoch 5], [iter 1300 of 4500],[train loss 0.92412], [train acc 0.63846]\n",
      "[epoch 5], [iter 1400 of 4500],[train loss 0.91599], [train acc 0.64286]\n",
      "[epoch 5], [iter 1500 of 4500],[train loss 0.91637], [train acc 0.64400]\n",
      "[epoch 5], [iter 1600 of 4500],[train loss 0.91986], [train acc 0.64250]\n",
      "[epoch 5], [iter 1700 of 4500],[train loss 0.92072], [train acc 0.64294]\n",
      "[epoch 5], [iter 1800 of 4500],[train loss 0.91822], [train acc 0.64444]\n",
      "[epoch 5], [iter 1900 of 4500],[train loss 0.91744], [train acc 0.64474]\n",
      "[epoch 5], [iter 2000 of 4500],[train loss 0.91895], [train acc 0.64333]\n",
      "[epoch 5], [iter 2100 of 4500],[train loss 0.92382], [train acc 0.64159]\n",
      "[epoch 5], [iter 2200 of 4500],[train loss 0.92503], [train acc 0.64030]\n",
      "[epoch 5], [iter 2300 of 4500],[train loss 0.92674], [train acc 0.63957]\n",
      "[epoch 5], [iter 2400 of 4500],[train loss 0.92788], [train acc 0.63847]\n",
      "[epoch 5], [iter 2500 of 4500],[train loss 0.93217], [train acc 0.63480]\n",
      "[epoch 5], [iter 2600 of 4500],[train loss 0.92904], [train acc 0.63679]\n",
      "[epoch 5], [iter 2700 of 4500],[train loss 0.92773], [train acc 0.63704]\n",
      "[epoch 5], [iter 2800 of 4500],[train loss 0.92567], [train acc 0.63786]\n",
      "[epoch 5], [iter 2900 of 4500],[train loss 0.92741], [train acc 0.63782]\n",
      "[epoch 5], [iter 3000 of 4500],[train loss 0.92643], [train acc 0.63878]\n",
      "[epoch 5], [iter 3100 of 4500],[train loss 0.92600], [train acc 0.63935]\n",
      "[epoch 5], [iter 3200 of 4500],[train loss 0.92423], [train acc 0.63990]\n",
      "[epoch 5], [iter 3300 of 4500],[train loss 0.92155], [train acc 0.64131]\n",
      "[epoch 5], [iter 3400 of 4500],[train loss 0.91865], [train acc 0.64304]\n",
      "[epoch 5], [iter 3500 of 4500],[train loss 0.91672], [train acc 0.64410]\n",
      "[epoch 5], [iter 3600 of 4500],[train loss 0.91714], [train acc 0.64444]\n",
      "[epoch 5], [iter 3700 of 4500],[train loss 0.91472], [train acc 0.64568]\n",
      "[epoch 5], [iter 3800 of 4500],[train loss 0.91345], [train acc 0.64596]\n",
      "[epoch 5], [iter 3900 of 4500],[train loss 0.91412], [train acc 0.64573]\n",
      "[epoch 5], [iter 4000 of 4500],[train loss 0.91463], [train acc 0.64558]\n",
      "[epoch 5], [iter 4100 of 4500],[train loss 0.91499], [train acc 0.64545]\n",
      "[epoch 5], [iter 4200 of 4500],[train loss 0.91564], [train acc 0.64556]\n",
      "[epoch 5], [iter 4300 of 4500],[train loss 0.91600], [train acc 0.64535]\n",
      "[epoch 5], [iter 4400 of 4500],[train loss 0.91483], [train acc 0.64614]\n",
      "[epoch 5], [iter 4500 of 4500],[train loss 0.91248], [train acc 0.64763]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.88331], [val acc 0.66185]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 :\n",
      "*****************************************************\n",
      "Complete in 75m 52s\n",
      "best record: [epoch 5], [val loss 0.88331], [val acc 0.66185]\n",
      "*****************************************************\n",
      "\n",
      "Total run Complete in 380m 8s\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "Starting Training resnet_5e_Adam_GS3\n",
      "[epoch 1], [iter 100 of 211],[train loss 1.45199], [train acc 0.37625]\n",
      "[epoch 1], [iter 200 of 211],[train loss 1.37918], [train acc 0.39852]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.34803], [val acc 0.41061]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 :\n",
      "*****************************************************\n",
      "Complete in 2m 30s\n",
      "best record: [epoch 1], [val loss 1.34803], [val acc 0.41061]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 of 211],[train loss 1.27764], [train acc 0.44031]\n",
      "[epoch 2], [iter 200 of 211],[train loss 1.26132], [train acc 0.44312]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.27925], [val acc 0.42345]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 :\n",
      "*****************************************************\n",
      "Complete in 2m 29s\n",
      "best record: [epoch 2], [val loss 1.27925], [val acc 0.42345]\n",
      "*****************************************************\n",
      "[epoch 3], [iter 100 of 211],[train loss 1.21524], [train acc 0.46016]\n",
      "[epoch 3], [iter 200 of 211],[train loss 1.19638], [train acc 0.46820]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.63790], [val acc 0.39353]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 :\n",
      "*****************************************************\n",
      "Complete in 2m 21s\n",
      "best record: [epoch 3], [val loss 1.63790], [val acc 0.39353]\n",
      "*****************************************************\n",
      "[epoch 4], [iter 100 of 211],[train loss 1.14585], [train acc 0.48969]\n",
      "[epoch 4], [iter 200 of 211],[train loss 1.14901], [train acc 0.49188]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.18733], [val acc 0.47626]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 :\n",
      "*****************************************************\n",
      "Complete in 2m 18s\n",
      "best record: [epoch 4], [val loss 1.18733], [val acc 0.47626]\n",
      "*****************************************************\n",
      "[epoch 5], [iter 100 of 211],[train loss 1.13185], [train acc 0.50953]\n",
      "[epoch 5], [iter 200 of 211],[train loss 1.12864], [train acc 0.50898]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.16190], [val acc 0.48486]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 :\n",
      "*****************************************************\n",
      "Complete in 2m 24s\n",
      "best record: [epoch 5], [val loss 1.16190], [val acc 0.48486]\n",
      "*****************************************************\n",
      "\n",
      "Total run Complete in 12m 2s\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "Starting Training vgg_5e_Adam_GS4\n",
      "[epoch 1], [iter 100 of 211],[train loss 1.74392], [train acc 0.28125]\n",
      "[epoch 1], [iter 200 of 211],[train loss 1.62405], [train acc 0.29945]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.69118], [val acc 0.20422]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 :\n",
      "*****************************************************\n",
      "Complete in 2m 14s\n",
      "best record: [epoch 1], [val loss 1.69118], [val acc 0.20422]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 100 of 211],[train loss 1.44490], [train acc 0.35734]\n",
      "[epoch 2], [iter 200 of 211],[train loss 1.41414], [train acc 0.36820]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.62884], [val acc 0.27737]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 :\n",
      "*****************************************************\n",
      "Complete in 2m 18s\n",
      "best record: [epoch 2], [val loss 1.62884], [val acc 0.27737]\n",
      "*****************************************************\n",
      "[epoch 3], [iter 100 of 211],[train loss 1.39144], [train acc 0.37719]\n",
      "[epoch 3], [iter 200 of 211],[train loss 1.36434], [train acc 0.39320]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.39426], [val acc 0.37827]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 :\n",
      "*****************************************************\n",
      "Complete in 2m 18s\n",
      "best record: [epoch 3], [val loss 1.39426], [val acc 0.37827]\n",
      "*****************************************************\n",
      "[epoch 4], [iter 100 of 211],[train loss 1.28713], [train acc 0.42859]\n",
      "[epoch 4], [iter 200 of 211],[train loss 1.27437], [train acc 0.43172]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.29718], [val acc 0.43907]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 :\n",
      "*****************************************************\n",
      "Complete in 2m 19s\n",
      "best record: [epoch 4], [val loss 1.29718], [val acc 0.43907]\n",
      "*****************************************************\n",
      "[epoch 5], [iter 100 of 211],[train loss 1.23422], [train acc 0.45141]\n",
      "[epoch 5], [iter 200 of 211],[train loss 1.23232], [train acc 0.45344]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.24746], [val acc 0.45506]\n",
      "------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 :\n",
      "*****************************************************\n",
      "Complete in 2m 19s\n",
      "best record: [epoch 5], [val loss 1.24746], [val acc 0.45506]\n",
      "*****************************************************\n",
      "\n",
      "Total run Complete in 11m 26s\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "Starting Training efficientnet_5e_Adam_GS5\n",
      "[epoch 1], [iter 100 of 4500],[train loss 1.85376], [train acc 0.23333]\n",
      "[epoch 1], [iter 200 of 4500],[train loss 1.82948], [train acc 0.22167]\n",
      "[epoch 1], [iter 300 of 4500],[train loss 1.79501], [train acc 0.22667]\n",
      "[epoch 1], [iter 400 of 4500],[train loss 1.79185], [train acc 0.21583]\n",
      "[epoch 1], [iter 500 of 4500],[train loss 1.78287], [train acc 0.21400]\n",
      "[epoch 1], [iter 600 of 4500],[train loss 1.77216], [train acc 0.21389]\n",
      "[epoch 1], [iter 700 of 4500],[train loss 1.75659], [train acc 0.21952]\n",
      "[epoch 1], [iter 800 of 4500],[train loss 1.74653], [train acc 0.22000]\n",
      "[epoch 1], [iter 900 of 4500],[train loss 1.73882], [train acc 0.22185]\n",
      "[epoch 1], [iter 1000 of 4500],[train loss 1.72982], [train acc 0.22600]\n",
      "[epoch 1], [iter 1100 of 4500],[train loss 1.72177], [train acc 0.22848]\n",
      "[epoch 1], [iter 1200 of 4500],[train loss 1.71374], [train acc 0.22972]\n",
      "[epoch 1], [iter 1300 of 4500],[train loss 1.70377], [train acc 0.23282]\n",
      "[epoch 1], [iter 1400 of 4500],[train loss 1.70007], [train acc 0.23310]\n",
      "[epoch 1], [iter 1500 of 4500],[train loss 1.69371], [train acc 0.23356]\n",
      "[epoch 1], [iter 1600 of 4500],[train loss 1.68849], [train acc 0.23542]\n",
      "[epoch 1], [iter 1700 of 4500],[train loss 1.68495], [train acc 0.23627]\n",
      "[epoch 1], [iter 1800 of 4500],[train loss 1.68184], [train acc 0.23833]\n",
      "[epoch 1], [iter 1900 of 4500],[train loss 1.67868], [train acc 0.23965]\n",
      "[epoch 1], [iter 2000 of 4500],[train loss 1.67443], [train acc 0.24100]\n",
      "[epoch 1], [iter 2100 of 4500],[train loss 1.66822], [train acc 0.24365]\n",
      "[epoch 1], [iter 2200 of 4500],[train loss 1.66629], [train acc 0.24394]\n",
      "[epoch 1], [iter 2300 of 4500],[train loss 1.66082], [train acc 0.24594]\n",
      "[epoch 1], [iter 2400 of 4500],[train loss 1.65665], [train acc 0.24625]\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch\n",
    "\n",
    "for i in g_search.iterrows():\n",
    "    \n",
    "    # extract gridsearch features\n",
    "    model_dict['epochs'] = i[1]['epochs']\n",
    "    model_dict['pretrained_model'] = i[1]['pretrained_model']\n",
    "    model_dict['optimizer_name'] = i[1]['optimizer']\n",
    "    me = i[1]['epochs']\n",
    "    mn = i[1]['pretrained_model']\n",
    "    mo = i[1]['optimizer']\n",
    "    model_dict['alias'] = i[0]\n",
    "    model_dict['tuned_model_name'] = f'{mn}_{me}e_{mo}_GS{i[0]}'\n",
    "    direc = model_dict['mod_directory']\n",
    "    nam = model_dict['tuned_model_name']\n",
    "    \n",
    "    # set batch size\n",
    "    if model_dict['pretrained_model'] == 'efficientnet':\n",
    "        model_dict['batch_size'] = 3\n",
    "    else: \n",
    "        model_dict['batch_size'] = 64\n",
    "    \n",
    "    # Load each model\n",
    "    model_ft, input_size = initialize_model(model_name = model_dict['pretrained_model'], \n",
    "                                            num_classes = len(data.label.unique()),\n",
    "                                            feature_extract = False, \n",
    "                                            use_pretrained=True)\n",
    "    \n",
    "    # Move model to GPU\n",
    "    model = model_ft.to(model_dict['device'])\n",
    "    \n",
    "    model_dict.update({\n",
    "                       'model':model,\n",
    "                       'criterion': nn.CrossEntropyLoss().to(model_dict['device']),\n",
    "    })\n",
    "    \n",
    "    # Define optimizer options:\n",
    "    if model_dict['optimizer_name'] == 'SGD':\n",
    "        model_dict.update({'optimizer': optim.SGD(model.parameters(), lr=model_dict['lr'])})\n",
    "    elif model_dict['optimizer_name'] == 'Adam':\n",
    "        model_dict.update({'optimizer': optim.Adam(model.parameters(), lr=model_dict['lr'])})\n",
    "    elif model_dict['optimizer_name'] == 'AdamW':\n",
    "        model_dict.update({'optimizer': optim.AdamW(model.parameters(), lr=model_dict['lr'])})\n",
    "    \n",
    "    # Update dictionary\n",
    "    model_dict['resize'] = int(input_size/.85)\n",
    "\n",
    "    \n",
    "    # Set Transforms\n",
    "    transform_header = [\n",
    "                        transforms.Resize(model_dict['resize']), #255\n",
    "                        transforms.CenterCrop(input_size)\n",
    "                        ]\n",
    "\n",
    "    transform_body = [\n",
    "                      transforms.RandomHorizontalFlip(), # a\n",
    "                      transforms.RandomVerticalFlip(), # b\n",
    "                      transforms.RandomRotation(20), # c\n",
    "                      transforms.RandomCrop(size=(input_size,input_size)), # d\n",
    "#                       transforms.RandomInvert(), transforms.RandomPosterize(bits=2), # e\n",
    "#                       transforms.RandomAdjustSharpness(sharpness_factor=2), # f\n",
    "#                       transforms.RandomSolarize(threshold=192.0), # g\n",
    "#                       transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1) # h\n",
    "                      ]\n",
    "\n",
    "    transform_footer = [transforms.ToTensor(), \n",
    "                      transforms.Normalize(mean=[.541, .414, .382], std=[.256,.215,.209])]\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "                                      transforms.Resize(model_dict['resize']),\n",
    "                                      transforms.CenterCrop(input_size),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize(mean=[.541, .414, .382], std=[.256,.215,.209])\n",
    "                                    ])\n",
    "    \n",
    "    test_loader = build_loader(mode = 'test', df = test, transform = val_transform, batch_size = model_dict['batch_size'], num_workers = model_dict['num_workers'])\n",
    "    val_loader = build_loader(mode = 'val', df = val, transform = val_transform, batch_size = model_dict['batch_size'], num_workers = model_dict['num_workers'])   \n",
    "    \n",
    "    transform_list = transform_header + transform_body + transform_footer\n",
    "    train_transform = transforms.Compose(transform_list)\n",
    "    train_loader = build_loader(mode = 'train', df = train, transform = train_transform, batch_size = model_dict['batch_size'], num_workers = model_dict['num_workers'])\n",
    "\n",
    "\n",
    "    loaders = {'train_loader':train_loader,\n",
    "                            'val_loader': val_loader,\n",
    "                            'test_loader': test_loader}\n",
    "    model_dict['loader'] = loaders\n",
    "\n",
    "    pred_df, val_scores, tot_time = train_model(model_dict = model_dict)\n",
    "\n",
    "    acc, f1, f2, f5, prec, rec, d_0, d_1, d_2, d_3, d_4 = val_scores\n",
    "    \n",
    "\n",
    "    pred_df.to_pickle(f'{direc}/{nam}_preds.pkl')\n",
    "    \n",
    "    col_dict = {\n",
    "#              'model': pd.Series(dtype = 'int'),\n",
    "#              'file': pd.Series(dtype = 'str'),\n",
    "             'tuned_model': model_dict['tuned_model_name'],\n",
    "             'transform': model_dict['transform'],\n",
    "             'lr': model_dict['lr'],\n",
    "             'pretrained_model': model_dict['pretrained_model'],\n",
    "             'optimizer': model_dict['optimizer_name'],\n",
    "             'epochs': model_dict['epochs'],\n",
    "#              'num_classes': model_dict['num_classes'],\n",
    "             'batch_size': model_dict['batch_size'],\n",
    "             'workers': model_dict['num_workers'],\n",
    "             'train_time': tot_time,\n",
    "             'data_split': model_dict['split'],\n",
    "             'label_set': model_dict['cl'],\n",
    "             'accur': acc,\n",
    "             'F1': f1,\n",
    "             'F0.5': f5,\n",
    "             'F2': f2,\n",
    "             'benign_accur': d_0,\n",
    "             'noncancerous_accur': d_1,\n",
    "             'malignant_accur': d_2,\n",
    "             'infection_accur': d_3,\n",
    "             'unclassified_accur': d_4\n",
    "    }\n",
    "    \n",
    "#     print(tdf.iloc[:i[0]+1][['transform', 'lr', 'accur']])\n",
    "    add_results(model_dict['results_file'], direc, pd.DataFrame(col_dict, index = [i[0]]))\n",
    "    print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WtiFA177sreH",
    "zV8Kq9caqc_m"
   ],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
