{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d81821e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e59d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter kernelspec uninstall w210_env --y\n",
    "\n",
    "# https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23c327a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/teledermatologyAI_capstone/notebooks/modelling'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f9e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/teledermatologyAI_capstone\n"
     ]
    }
   ],
   "source": [
    "cd /home/ec2-user/SageMaker/teledermatologyAI_capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852172ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new virtual env\n",
    "# !python -m venv w210_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this for every instance spin up\n",
    "# !source w210_env/bin/activate && ipython kernel install --user --name w210_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21357dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.4 MB 128.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image\n",
      "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.0 MB 27.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting basic-image-eda\n",
      "  Downloading basic_image_eda-0.0.3-py3-none-any.whl (9.8 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 88.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "Collecting pandas_profiling\n",
      "  Downloading pandas_profiling-3.4.0-py2.py3-none-any.whl (315 kB)\n",
      "\u001b[K     |████████████████████████████████| 315 kB 114.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting awswrangler\n",
      "  Downloading awswrangler-2.17.0-py3-none-any.whl (251 kB)\n",
      "\u001b[K     |████████████████████████████████| 251 kB 130.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipywidgets\n",
      "  Downloading ipywidgets-8.0.2-py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 133.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting coremltools\n",
      "  Downloading coremltools-6.0-cp38-none-manylinux1_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 142.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch_lr_finder\n",
      "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
      "Collecting pytorchtools\n",
      "  Downloading pytorchtools-0.0.2-py2.py3-none-any.whl (3.1 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp38-cp38-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.3 MB 129.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "Collecting python-dateutil>=2.8.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 90.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.20.3\n",
      "  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.1 MB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 117.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 36.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 26.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 21.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
      "\u001b[K     |████████████████████████████████| 295 kB 125.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.4.1\n",
      "  Downloading imageio-2.22.4-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 128.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2022.10.10-py3-none-any.whl (210 kB)\n",
      "\u001b[K     |████████████████████████████████| 210 kB 129.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.4.1\n",
      "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.8 MB 70.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.2\n",
      "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 124.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 132.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting visions[type_image_path]==0.7.5\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "\u001b[K     |████████████████████████████████| 102 kB 129.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<2.29,>=2.24.0\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting pydantic<1.11,>=1.8.1\n",
      "  Downloading pydantic-1.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting missingno<0.6,>=0.4.2\n",
      "  Downloading missingno-0.5.1-py3-none-any.whl (8.7 kB)\n",
      "Collecting PyYAML<6.1,>=5.0.0\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[K     |████████████████████████████████| 701 kB 42.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (696 kB)\n",
      "\u001b[K     |████████████████████████████████| 696 kB 132.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm<4.65,>=4.48.2\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 7.7 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 130.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting htmlmin==0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "Collecting multimethod<1.10,>=1.4\n",
      "  Downloading multimethod-1.9-py3-none-any.whl (10 kB)\n",
      "Collecting statsmodels<0.14,>=0.13.2\n",
      "  Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 121.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2<3.2,>=2.11.1\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 132.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrs>=19.3.0\n",
      "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 16.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tangled-up-in-unicode>=0.0.4\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 113.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imagehash\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "\u001b[K     |████████████████████████████████| 296 kB 119.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting joblib>=0.14.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 73.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.1.0\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 26 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 129.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 63.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting redshift-connector<2.1.0,>=2.0.889\n",
      "  Downloading redshift_connector-2.0.909-py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 121.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow<8.1.0,>=2.0.0\n",
      "  Downloading pyarrow-8.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 29.4 MB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gremlinpython<4.0.0,>=3.5.2\n",
      "  Downloading gremlinpython-3.6.1-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 6.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opensearch-py<3,>=1\n",
      "  Downloading opensearch_py-2.0.0-py2.py3-none-any.whl (204 kB)\n",
      "\u001b[K     |████████████████████████████████| 204 kB 136.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pg8000<2.0.0,>=1.20.0\n",
      "  Downloading pg8000-1.29.3-py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 257 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting progressbar2<5.0.0,>=4.0.0\n",
      "  Downloading progressbar2-4.2.0-py2.py3-none-any.whl (27 kB)\n",
      "Collecting openpyxl<3.1.0,>=3.0.0\n",
      "  Downloading openpyxl-3.0.10-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 32.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<2.0.0,>=1.27.11\n",
      "  Downloading botocore-1.29.6-py3-none-any.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 121.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-aws4auth<2.0.0,>=1.1.1\n",
      "  Downloading requests_aws4auth-1.1.2-py2.py3-none-any.whl (24 kB)\n",
      "Collecting jsonpath-ng<2.0.0,>=1.5.3\n",
      "  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\n",
      "Collecting backoff<3.0.0,>=1.11.1\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting boto3<2.0.0,>=1.24.11\n",
      "  Downloading boto3-1.26.6-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 130.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pymysql<2.0.0,>=1.0.0\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 4.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting isodate<1.0.0,>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 1.8 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting aenum<4.0.0,>=1.4.5\n",
      "  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 137.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp<=3.8.1,>=3.8.0\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 93.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 131.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[K     |████████████████████████████████| 262 kB 57.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 116.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting ply\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting scramp>=1.4.3\n",
      "  Downloading scramp-1.4.4-py3-none-any.whl (13 kB)\n",
      "Collecting python-utils>=3.0.0\n",
      "  Downloading python_utils-3.4.5-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: setuptools in ./w210_env/lib/python3.8/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler->-r requirements.txt (line 8)) (56.0.0)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.7.0\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 90.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml>=4.6.5\n",
      "  Downloading lxml-4.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting asn1crypto>=1.5.1\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 76.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-widgets~=3.0\n",
      "  Downloading jupyterlab_widgets-3.0.3-py3-none-any.whl (384 kB)\n",
      "\u001b[K     |████████████████████████████████| 384 kB 62.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython>=6.1.0\n",
      "  Downloading ipython-8.6.0-py3-none-any.whl (761 kB)\n",
      "\u001b[K     |████████████████████████████████| 761 kB 97.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipykernel>=4.5.1\n",
      "  Downloading ipykernel-6.17.1-py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 133.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting widgetsnbextension~=4.0\n",
      "  Downloading widgetsnbextension-4.0.3-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 104.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting traitlets>=4.3.1\n",
      "  Downloading traitlets-5.5.0-py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 122.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 126.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib-inline>=0.1\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting jupyter-client>=6.1.12\n",
      "  Downloading jupyter_client-7.4.4-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 93.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyzmq>=17\n",
      "  Downloading pyzmq-24.0.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 118.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting debugpy>=1.0\n",
      "  Downloading debugpy-1.6.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 119.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tornado>=6.1\n",
      "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "\u001b[K     |████████████████████████████████| 423 kB 61.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting prompt-toolkit<3.1.0,>3.0.1\n",
      "  Downloading prompt_toolkit-3.0.32-py3-none-any.whl (382 kB)\n",
      "\u001b[K     |████████████████████████████████| 382 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting stack-data\n",
      "  Downloading stack_data-0.6.0-py3-none-any.whl (24 kB)\n",
      "Collecting pexpect>4.3\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 18.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jedi>=0.16\n",
      "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 28.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pygments>=2.4.0\n",
      "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
      "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 25.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting entrypoints\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting jupyter-core>=4.9.2\n",
      "  Downloading jupyter_core-5.0.0-py3-none-any.whl (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 5.0 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting platformdirs\n",
      "  Downloading platformdirs-2.5.3-py3-none-any.whl (14 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "Collecting protobuf<=3.20.1,>=3.1.0\n",
      "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 35.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 24.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch>=0.4.1\n",
      "  Downloading torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 890.2 MB 1.9 kB/s s eta 0:00:01     |████████████████████████▋       | 685.3 MB 141.8 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1 MB 9.6 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 94.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1 MB 7.7 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 49.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading asttokens-2.1.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting executing>=1.2.0\n",
      "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pure-eval\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[K     |████████████████████████████████| 532 kB 131.0 MB/s eta 0:00:01\n",
      "\u001b[?25hUsing legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for htmlmin, since package 'wheel' is not installed.\n",
      "Installing collected packages: six, urllib3, python-dateutil, pyparsing, jmespath, wheel, wcwidth, traitlets, pytz, pure-eval, ptyprocess, platformdirs, pillow, parso, packaging, numpy, multidict, kiwisolver, idna, frozenlist, fonttools, executing, cycler, botocore, asttokens, yarl, tornado, tangled-up-in-unicode, stack-data, soupsieve, scipy, s3transfer, pyzmq, PyWavelets, pygments, prompt-toolkit, pickleshare, pexpect, pandas, nvidia-cublas-cu11, networkx, nest-asyncio, multimethod, matplotlib-inline, matplotlib, jupyter-core, jedi, entrypoints, decorator, charset-normalizer, certifi, backcall, attrs, async-timeout, asn1crypto, aiosignal, visions, typing-extensions, seaborn, scramp, requests, python-utils, psutil, ply, patsy, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, mpmath, MarkupSafe, lxml, jupyter-client, joblib, isodate, ipython, imagehash, et-xmlfile, debugpy, boto3, beautifulsoup4, aiohttp, aenum, widgetsnbextension, tqdm, torch, tifffile, sympy, statsmodels, requests-aws4auth, redshift-connector, PyYAML, pymysql, pydantic, pyarrow, protobuf, progressbar2, phik, pg8000, opensearch-py, openpyxl, missingno, jupyterlab-widgets, jsonpath-ng, jinja2, ipykernel, imageio, htmlmin, gremlinpython, backoff, torchvision, torch-lr-finder, sklearn, scikit-image, pytorchtools, pandas-profiling, ipywidgets, coremltools, basic-image-eda, awswrangler\n",
      "    Running setup.py install for htmlmin ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed MarkupSafe-2.1.1 PyWavelets-1.4.1 PyYAML-6.0 aenum-3.1.11 aiohttp-3.8.1 aiosignal-1.3.1 asn1crypto-1.5.1 asttokens-2.1.0 async-timeout-4.0.2 attrs-22.1.0 awswrangler-2.17.0 backcall-0.2.0 backoff-2.2.1 basic-image-eda-0.0.3 beautifulsoup4-4.11.1 boto3-1.26.6 botocore-1.29.6 certifi-2022.9.24 charset-normalizer-2.1.1 coremltools-6.0 cycler-0.11.0 debugpy-1.6.3 decorator-5.1.1 entrypoints-0.4 et-xmlfile-1.1.0 executing-1.2.0 fonttools-4.38.0 frozenlist-1.3.3 gremlinpython-3.6.1 htmlmin-0.1.12 idna-3.4 imagehash-4.3.1 imageio-2.22.4 ipykernel-6.17.1 ipython-8.6.0 ipywidgets-8.0.2 isodate-0.6.1 jedi-0.18.1 jinja2-3.1.2 jmespath-1.0.1 joblib-1.2.0 jsonpath-ng-1.5.3 jupyter-client-7.4.4 jupyter-core-5.0.0 jupyterlab-widgets-3.0.3 kiwisolver-1.4.4 lxml-4.9.1 matplotlib-3.5.3 matplotlib-inline-0.1.6 missingno-0.5.1 mpmath-1.2.1 multidict-6.0.2 multimethod-1.9 nest-asyncio-1.5.6 networkx-2.8.8 numpy-1.23.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 openpyxl-3.0.10 opensearch-py-2.0.0 packaging-21.3 pandas-1.5.1 pandas-profiling-3.4.0 parso-0.8.3 patsy-0.5.3 pexpect-4.8.0 pg8000-1.29.3 phik-0.12.2 pickleshare-0.7.5 pillow-9.3.0 platformdirs-2.5.3 ply-3.11 progressbar2-4.2.0 prompt-toolkit-3.0.32 protobuf-3.20.1 psutil-5.9.4 ptyprocess-0.7.0 pure-eval-0.2.2 pyarrow-8.0.0 pydantic-1.10.2 pygments-2.13.0 pymysql-1.0.2 pyparsing-3.0.9 python-dateutil-2.8.2 python-utils-3.4.5 pytorchtools-0.0.2 pytz-2022.6 pyzmq-24.0.1 redshift-connector-2.0.909 requests-2.28.1 requests-aws4auth-1.1.2 s3transfer-0.6.0 scikit-image-0.19.3 scipy-1.9.3 scramp-1.4.4 seaborn-0.12.1 six-1.16.0 sklearn-0.0.post1 soupsieve-2.3.2.post1 stack-data-0.6.0 statsmodels-0.13.5 sympy-1.11.1 tangled-up-in-unicode-0.2.0 tifffile-2022.10.10 torch-1.13.0 torch-lr-finder-0.2.1 torchvision-0.14.0 tornado-6.2 tqdm-4.64.1 traitlets-5.5.0 typing-extensions-4.4.0 urllib3-1.26.12 visions-0.7.5 wcwidth-0.2.5 wheel-0.38.4 widgetsnbextension-4.0.3 yarl-1.8.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/SageMaker/teledermatologyAI_capstone/w210_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# run this if added new packages\n",
    "# !./w210_env/bin/pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac56e475",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13876/3862490900.py\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mp_image\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "# expand pandas df rows/column widths etc.\n",
    "pd.set_option(\"display.max_rows\", None, # display all rows\n",
    "              \"display.max_columns\", None, # display all columns\n",
    "              \"display.max_colwidth\", None, # expand column width\n",
    "              \"display.html.use_mathjax\", False\n",
    "             ) # disable Latex style mathjax rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits: https://github.com/yuliyabohdan/Skin-diseases-classification-Dermnet-/blob/main/skin_diseases_clas_ResNet50.ipynb\n",
    "data_split = 'split_3'\n",
    "data_dir = 'data_class_folder3'\n",
    "\n",
    "DIR = data_dir\n",
    "DIR_TRAIN = f'{DIR}/train/'\n",
    "DIR_VAL = f'{DIR}/val/'\n",
    "DIR_TEST = f'{DIR}/test/' \n",
    "\n",
    "classes = sorted(os.listdir(DIR_TRAIN))\n",
    "print(f'Data split: {DIR}')\n",
    "print(f'Total classes: {len(classes)}')\n",
    "\n",
    "# total train, val and test images\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "test_count = 0\n",
    "\n",
    "classes_df = []\n",
    "for _class in classes:\n",
    "    class_dict = {}\n",
    "    train_count += len(os.listdir(DIR_TRAIN + _class))\n",
    "    val_count += len(os.listdir(DIR_VAL + _class))\n",
    "    test_count += len(os.listdir(DIR_TEST + _class))\n",
    "    class_dict.update({'Class': _class, \n",
    "                       'Train': len(os.listdir(DIR_TRAIN + _class)),\n",
    "                       'Val': len(os.listdir(DIR_VAL + _class)),\n",
    "                       'Test': len(os.listdir(DIR_TEST + _class)) })\n",
    "    classes_df.append(class_dict)\n",
    "\n",
    "print(f'Total num train images: {train_count}')\n",
    "print(f'Total num val images: {val_count}')\n",
    "print(f'Total num test images: {test_count}')\n",
    "print(pd.DataFrame(classes_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a241e2",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "def initialize_model(model_name, num_classes, feature_extract=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(weights='DEFAULT')\n",
    "        #we can select any possible variation of ResNet such as Resnet18, Resnet34, Resnet50, Resnet101, and Resnet152\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538cfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67959327/how-to-calculate-the-f1-score\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, patience):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('\\nEpoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:               \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                #update_bn_stats(model=model, data_loader=dataloaders[phase])  # if update_bn_stats\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                      # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                f1score = f1_score(labels.cpu().data, preds.cpu(), average='macro')\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} f1_score: {.4f}'.format(phase, epoch_loss, epoch_acc, f1score))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                \n",
    "#                 # early_stopping needs the validation loss to check if it has decresed, \n",
    "#                 # and if it has, it will make a checkpoint of the current model\n",
    "#                 early_stopping(epoch_loss, model)\n",
    "#                 if early_stopping.early_stop:\n",
    "#                     best_acc = epoch_acc\n",
    "#                     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "#                     print(\"Early stopping\")\n",
    "#                     break     \n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_loss_history.append(epoch_loss)\n",
    "        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "   \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f'Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}')    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a1b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y - find the img from class x labelled as class y \n",
    "def test(model, dl, x, y, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    images_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images_list.append(images.cpu().numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "    \n",
    "    for n in range(60):\n",
    "        for i in range(32):\n",
    "            if (true_labels[n][i] == x)  & (predictions[n][i] == y):\n",
    "                #inv_tensor = inv_normalize(image_list[n][i]])\n",
    "                plt.imshow(np.transpose(images_list[n][i], (1, 2, 0)))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167c10a6",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50633e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = [1, 2]\n",
    "learning_rate_list = [0.000559, 0.0001]\n",
    "batch_size_list = [64]\n",
    "optimizer_list = [\n",
    "    'Adam', \n",
    "    'AdamW', \n",
    "#     'SGD'\n",
    "]\n",
    "\n",
    "model_list = [\n",
    "    'resnet',\n",
    "#     'densenet'\n",
    "]\n",
    "\n",
    "grid_list = [\n",
    "    epochs_list,\n",
    "    learning_rate_list,\n",
    "    batch_size_list,\n",
    "    optimizer_list,\n",
    "    model_list\n",
    "            ]\n",
    "\n",
    "grid = list(itertools.product(*grid_list))\n",
    "random.shuffle(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64682b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mean = (0.676, 0.542, 0.519)\n",
    "norm_std = (0.290, 0.226, 0.237)\n",
    "num_workers = 16\n",
    "feature_extract=True\n",
    "num_loop = 2\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'dataset',\n",
    "    'num_classes',\n",
    "    'model',\n",
    "    'val_accuracy',\n",
    "    'train_time (min)',\n",
    "    'epochs',\n",
    "    'learning_rate',\n",
    "    'optimizer',\n",
    "    'batch_size',\n",
    "])\n",
    "\n",
    "for i in range(num_loop):\n",
    "    print(f'''\n",
    "  {i+1}. epochs={grid[i][0]} \n",
    "     learning_rate={grid[i][1]} \n",
    "     batch_size={grid[i][2]} \n",
    "     optimizer={grid[i][3]}\n",
    "     model={grid[i][4]}\n",
    "        ''') \n",
    "    start_time = time.time()#datetime.now(timezone('America/Chicago')).strftime('%Y%m%d-%H%M%S')\n",
    "    model_ft, input_size = initialize_model(model_name=grid[i][4], num_classes=len(classes), \n",
    "                                            feature_extract=feature_extract)\n",
    "    \n",
    "    train_dataset =ImageFolder(root = DIR_TRAIN, transform=transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.RandomCrop(size=(input_size, input_size)),\n",
    "        transforms.ToTensor(), transforms.Normalize(norm_mean, norm_std)]))\n",
    "\n",
    "    valid_dataset = ImageFolder(root = DIR_VAL, transform=transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean, norm_std)]))\n",
    "\n",
    "    test_dataset = ImageFolder(root = DIR_TEST, transform=transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(norm_mean, norm_std)]))\n",
    "    \n",
    "    dataloaders_dict = {}\n",
    "    dataloaders_dict['train'] = DataLoader(train_dataset, batch_size=grid[i][2], \n",
    "                                           shuffle=True, num_workers=num_workers)\n",
    "    dataloaders_dict['val'] = DataLoader(valid_dataset, batch_size=grid[i][2], \n",
    "                                         shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "    dataloader_test = DataLoader(test_dataset, batch_size=grid[i][2], shuffle=False, \n",
    "                                 num_workers=num_workers, drop_last=False)\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model_ft = model_ft.to(device)\n",
    "    \n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  fine tuning we will be updating all parameters. However, if we are \n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model_ft.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "                             \n",
    "    optimizer_ft = getattr(torch.optim, grid[i][3])(model_ft.parameters(), lr=grid[i][1])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, \n",
    "                                 num_epochs=grid[i][0], patience=3)\n",
    "    \n",
    "    end_time = time.time() - start_time\n",
    "    \n",
    "    row = {\n",
    "        'dataset': data_split,\n",
    "        'num_classes': int(len(classes)),\n",
    "        'model': grid[i][4],\n",
    "        'val_accuracy': f'{hist[0].item():.2f}',\n",
    "        'train_time (min)': f'{end_time/60:.0f}',\n",
    "        'epochs': int(grid[i][0]),\n",
    "        'learning_rate': grid[i][1],\n",
    "        'optimizer': grid[i][3],\n",
    "        'batch_size': int(grid[i][2])\n",
    "    }\n",
    "    \n",
    "    new_df = pd.DataFrame([row])\n",
    "    results_df = pd.concat([results_df, new_df], axis=0, ignore_index=True).sort_values('val_accuracy', ascending = False)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'{data_split}_resnet50'\n",
    "torch.save(model, f'model/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4add6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'model/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predictions = test_model(model, dataloader_test, normalize=True)\n",
    "c_matrix = confusion_matrix(true_labels, predictions, normalize='true')\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Confusion matrix\")\n",
    "sns.heatmap(c_matrix, cmap='Blues', annot=True, xticklabels=classes, yticklabels=classes, fmt='.1%', cbar=True)\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('true labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073b469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # False prediction\n",
    "# test(model, dataloader_test, 2, 0) #(potentially malignant skin tumors, non-cancerous skin condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7adc19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Correct prediction of autoimmune disorder\n",
    "# test(model, dataloader_test, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trace model\n",
    "\n",
    "# # must be the same size a minibatch with 1 example image\n",
    "# example = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# # move model back to cpu, do tracing, and optimize\n",
    "# model_conv = model.to('cpu')\n",
    "# traced_script_module = torch.jit.trace(model_conv, example)\n",
    "# torchscript_model_optimized = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "# # save optimized model for mobile\n",
    "# PATH = f'model/{model_name}_traced.pt'\n",
    "# torchscript_model_optimized.save(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf74bc",
   "metadata": {},
   "source": [
    "# Conversion from PyTorch to CoreML\n",
    "https://github.com/vincentfpgarcia/from-pytorch-to-coreml/blob/master/step6_part1.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4220af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "from coremltools.converters import ClassifierConfig\n",
    "\n",
    "classifier_config = ClassifierConfig(class_labels=class_list)\n",
    "\n",
    "model = torch.load(f'model/{model_name}.pt')\n",
    "\n",
    "# Create dummy input\n",
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "model_conv = model.to('cpu')\n",
    "\n",
    "# Trace the model\n",
    "traced_model = torch.jit.trace(model_conv, dummy_input)\n",
    "\n",
    "# Create the input image type\n",
    "input_image = ct.ImageType(name=\"my_input\", shape=(1, 3, 224, 224), scale=1/255)\n",
    "\n",
    "# Convert the model\n",
    "coreml_model = ct.convert(traced_model, inputs=[input_image], classifier_config=classifier_config)\n",
    "\n",
    "# Modify the output's name to \"my_output\" in the spec\n",
    "spec = coreml_model.get_spec()\n",
    "ct.utils.rename_feature(spec, \"var_840\", \"my_output\")\n",
    "\n",
    "# Re-create the model from the updated spec\n",
    "coreml_model_updated = ct.models.MLModel(spec)\n",
    "\n",
    "# Save the CoreML model\n",
    "coremlmodel_name = 'skindiseases5'\n",
    "coreml_model_updated.save(f'model/{coremlmodel_name}.mlmodel')\n",
    "\n",
    "# Load the CoreML model\n",
    "model =  ct.models.MLModel(f'model/{coremlmodel_name}.mlmodel')\n",
    "\n",
    "# Display its specifications\n",
    "print()\n",
    "print(model)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# classes\n",
    "classes = ['Benign Marking or Mole',\n",
    "           'Non-Cancerous Skin Condition',\n",
    "           'Potentially Malignant Skin Tumors', \n",
    "           'Toxin, Fungal, Bug, Viral, or Bacterial Infections',\n",
    "           'Unclassified']\n",
    "\n",
    "# Load the test image\n",
    "image = Image.open('inference/Potentially Malignant Skin Tumors/melanoma.jpeg')\n",
    "\n",
    "# Prediction vector as a numpy array\n",
    "pred = model.predict({'my_input': image.resize((224, 224))})\n",
    "pred = pred['my_output']\n",
    "pred = pred.squeeze()\n",
    "\n",
    "# Display the most probable class\n",
    "idx = pred.argmax()\n",
    "print('Predicted class : %d (%s)' % (idx, classes[idx]))\n",
    "pred['classLabel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5e84c",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = ImageFolder(root = 'inference/', transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.676, 0.542, 0.519], std=[0.290, 0.226, 0.237])\n",
    "]))\n",
    "\n",
    "dataloader_inference = DataLoader(inference_dataset, batch_size=1, \n",
    "                                  shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "def inference_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    # device = torch.device('cpu')\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f'Inference Accuracy of the model: {float(num_correct)/float(total)*100:.2f}')    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(f'model/{model_name}_traced.pt')\n",
    "model = torch.load(f'model/{model_name}.pt')\n",
    "true_labels, predictions = inference_model(model, dataloader_inference, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd995240",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -czf model/model.tar.gz model/merged_resnet50.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp model/model.tar.gz s3://rubyhan-w210-datasets/model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w210_env",
   "language": "python",
   "name": "w210_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
