{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fdcdaa",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11453679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall \"opencv-python-headless\" --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96412217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install opencv-python-headless\n",
    "# %pip install scikit-image\n",
    "# %pip install basic-image-eda\n",
    "# %pip install seaborn\n",
    "# %pip install torchvision\n",
    "# %pip install sklearn\n",
    "# %pip install pandas_profiling\n",
    "# %pip install awswrangler\n",
    "# %pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f39264-672d-48c7-91f8-21d727d96dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b8d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mp_image\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import awswrangler as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9b117",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5524266",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f's3://rubyhan-w210-datasets/full_data.csv'\n",
    "full_df = wr.s3.read_csv(path=s3_path, index_col=0).rename(columns={'duplicated':'duplicate', 'class':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ce51c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>source</th>\n",
       "      <th>severity</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>duplicate</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split_1</th>\n",
       "      <th>split_2</th>\n",
       "      <th>split_3</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>split_4</th>\n",
       "      <th>split_5</th>\n",
       "      <th>split_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fissure-2</td>\n",
       "      <td>eczema photos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dermnet</td>\n",
       "      <td>unknown</td>\n",
       "      <td>./Data/dermnet/train/Nail Fungus and other Nai...</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id-reaction-10</td>\n",
       "      <td>eczema photos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dermnet</td>\n",
       "      <td>unknown</td>\n",
       "      <td>./Data/dermnet/train/Tinea Ringworm Candidiasi...</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id-reaction-7</td>\n",
       "      <td>eczema photos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dermnet</td>\n",
       "      <td>unknown</td>\n",
       "      <td>./Data/dermnet/train/Tinea Ringworm Candidiasi...</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fissure-5</td>\n",
       "      <td>eczema photos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dermnet</td>\n",
       "      <td>unknown</td>\n",
       "      <td>./Data/dermnet/train/Nail Fungus and other Nai...</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id-reaction-1</td>\n",
       "      <td>eczema photos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>dermnet</td>\n",
       "      <td>unknown</td>\n",
       "      <td>./Data/dermnet/train/Tinea Ringworm Candidiasi...</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>Non-Cancerous Skin Condition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id      diagnosis  age      sex localization   source severity  \\\n",
       "0       fissure-2  eczema photos  0.0  unknown      unknown  dermnet  unknown   \n",
       "1  id-reaction-10  eczema photos  0.0  unknown      unknown  dermnet  unknown   \n",
       "2   id-reaction-7  eczema photos  0.0  unknown      unknown  dermnet  unknown   \n",
       "3       fissure-5  eczema photos  0.0  unknown      unknown  dermnet  unknown   \n",
       "4   id-reaction-1  eczema photos  0.0  unknown      unknown  dermnet  unknown   \n",
       "\n",
       "                                                path  \\\n",
       "0  ./Data/dermnet/train/Nail Fungus and other Nai...   \n",
       "1  ./Data/dermnet/train/Tinea Ringworm Candidiasi...   \n",
       "2  ./Data/dermnet/train/Tinea Ringworm Candidiasi...   \n",
       "3  ./Data/dermnet/train/Nail Fungus and other Nai...   \n",
       "4  ./Data/dermnet/train/Tinea Ringworm Candidiasi...   \n",
       "\n",
       "                          label  duplicate dataset split_1 split_2 split_3  \\\n",
       "0  Non-Cancerous Skin Condition       True     NaN     NaN     NaN     NaN   \n",
       "1  Non-Cancerous Skin Condition       True     NaN     NaN     NaN     NaN   \n",
       "2  Non-Cancerous Skin Condition       True     NaN     NaN     NaN     NaN   \n",
       "3  Non-Cancerous Skin Condition       True     NaN     NaN     NaN     NaN   \n",
       "4  Non-Cancerous Skin Condition       True     NaN     NaN     NaN     NaN   \n",
       "\n",
       "                        label_1                       label_2  \\\n",
       "0  Non-Cancerous Skin Condition  Non-Cancerous Skin Condition   \n",
       "1  Non-Cancerous Skin Condition  Non-Cancerous Skin Condition   \n",
       "2  Non-Cancerous Skin Condition  Non-Cancerous Skin Condition   \n",
       "3  Non-Cancerous Skin Condition  Non-Cancerous Skin Condition   \n",
       "4  Non-Cancerous Skin Condition  Non-Cancerous Skin Condition   \n",
       "\n",
       "                        label_3 split_4 split_5 split_6  \n",
       "0  Non-Cancerous Skin Condition     NaN     NaN     NaN  \n",
       "1  Non-Cancerous Skin Condition     NaN     NaN     NaN  \n",
       "2  Non-Cancerous Skin Condition     NaN     NaN     NaN  \n",
       "3  Non-Cancerous Skin Condition     NaN     NaN     NaN  \n",
       "4  Non-Cancerous Skin Condition     NaN     NaN     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7acfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/teledermatologyAI_capstone\n"
     ]
    }
   ],
   "source": [
    "cd /home/studio-lab-user/teledermatologyAI_capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae1183",
   "metadata": {},
   "source": [
    "# Transforming Tabular to Folder Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eaca924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10418\n",
      "2103\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "# print(len(full_df[(full_df.source != 'ISIC_2020') & (full_df.dataset == 'train')]))\n",
    "# print(len(full_df[(full_df.source != 'ISIC_2020') & (full_df.dataset == 'val')]))\n",
    "# print(len(full_df[(full_df.source != 'ISIC_2020') & (full_df.dataset == 'test')]))\n",
    "\n",
    "data_split = 'split_3'\n",
    "data_dir = 'data_class_folder3'\n",
    "\n",
    "print(len(full_df[(full_df.source != 'ISIC_2020') & (full_df[data_split] == 'train')]))\n",
    "print(len(full_df[(full_df.source != 'ISIC_2020') & (full_df[data_split] == 'val')]))\n",
    "print(len(full_df[(full_df.source != 'ISIC_2020') & (full_df[data_split] == 'test')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b706f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df[full_df.path.str.contains('acne-keloidalis-1.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c4ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_list = full_df[~full_df[data_split].isna()].label.unique().tolist()\n",
    "# # class_list.remove('Autoimmue Disorder')\n",
    "\n",
    "# !mkdir -p $data_dir/train $data_dir/val $data_dir/test\n",
    "# for label in class_list:\n",
    "#     !mkdir -p $data_dir/train/\"$label\" \n",
    "#     !mkdir -p $data_dir/val/\"$label\" \n",
    "#     !mkdir -p $data_dir/test/\"$label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1966efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in full_df.iterrows():\n",
    "#     try:\n",
    "#         shutil.copy(row.path, f'{data_dir}/{row[data_split]}/{row.label}')\n",
    "#     except FileNotFoundError as e:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5723f9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: data_class_folder3\n",
      "Total classes: 5\n",
      "Total num train images: 10418\n",
      "Total num val images: 2103\n",
      "Total num test images: 1393\n",
      "                                               Class  Train  Val  Test\n",
      "0                             Benign Marking or Mole   1871  392   246\n",
      "1                       Non-Cancerous Skin Condition   2671  534   395\n",
      "2                  Potentially Malignant Skin Tumors   2274  452   290\n",
      "3  Toxin, Fungal, Bug, Viral, or Bacterial Infect...   2702  540   358\n",
      "4                                       Unclassified    900  185   104\n"
     ]
    }
   ],
   "source": [
    "# credits: https://github.com/yuliyabohdan/Skin-diseases-classification-Dermnet-/blob/main/skin_diseases_clas_ResNet50.ipynb\n",
    "\n",
    "DIR = data_dir\n",
    "DIR_TRAIN = f'{DIR}/train/'\n",
    "DIR_VAL = f'{DIR}/val/'\n",
    "DIR_TEST = f'{DIR}/test/' \n",
    "\n",
    "classes = sorted(os.listdir(DIR_TRAIN))\n",
    "print(f'Data split: {DIR}')\n",
    "print(f'Total classes: {len(classes)}')\n",
    "\n",
    "# total train, val and test images\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "test_count = 0\n",
    "\n",
    "classes_df = []\n",
    "for _class in classes:\n",
    "    class_dict = {}\n",
    "    train_count += len(os.listdir(DIR_TRAIN + _class))\n",
    "    val_count += len(os.listdir(DIR_VAL + _class))\n",
    "    test_count += len(os.listdir(DIR_TEST + _class))\n",
    "    class_dict.update({'Class': _class, \n",
    "                       'Train': len(os.listdir(DIR_TRAIN + _class)),\n",
    "                       'Val': len(os.listdir(DIR_VAL + _class)),\n",
    "                       'Test': len(os.listdir(DIR_TEST + _class)) })\n",
    "    classes_df.append(class_dict)\n",
    "\n",
    "print(f'Total num train images: {train_count}')\n",
    "print(f'Total num val images: {val_count}')\n",
    "print(f'Total num test images: {test_count}')\n",
    "print(pd.DataFrame(classes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f02103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign Marking or Mole 0\n",
      "Non-Cancerous Skin Condition 1\n",
      "Potentially Malignant Skin Tumors 2\n",
      "Toxin, Fungal, Bug, Viral, or Bacterial Infections 3\n",
      "Unclassified 4\n"
     ]
    }
   ],
   "source": [
    "# map class labels to integer index\n",
    "\n",
    "train_imgs = []\n",
    "val_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(DIR_TRAIN + _class):\n",
    "        train_imgs.append(f'{DIR_TRAIN}{_class}/{img}')\n",
    "    \n",
    "    for img in os.listdir(DIR_VAL + _class):\n",
    "        val_imgs.append(f'{DIR_VAL}{_class}/{img}')\n",
    "    \n",
    "    for img in os.listdir(DIR_TEST + _class):\n",
    "        test_imgs.append(f'{DIR_TEST}{_class}/{img}')\n",
    "\n",
    "classToInt = {classes[i]: i for i in range(len(classes))}\n",
    "intToClass = dict(map(reversed, classToInt.items()))\n",
    "\n",
    "for k, v in classToInt.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3940128-e225-45bc-8909-a3b31e740bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = []\n",
    "val_lst = []\n",
    "for _class, _classInt in classToInt.items():\n",
    "    for img in os.listdir(DIR_TRAIN + _class):\n",
    "        train_lst.append(f'{_classInt}\\t{_class}/{img}')\n",
    "        \n",
    "for _class, _classInt in classToInt.items():\n",
    "    for img in os.listdir(DIR_VAL + _class):\n",
    "        val_lst.append(f'{_classInt}\\t{_class}/{img}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8e5913-65df-450e-af1c-c6cf4ab2a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10418\n",
      "2103\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lst))\n",
    "print(len(val_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a965a6b4-f4bd-47a8-aee6-17808a448e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lst2 = [f'{i}\\t{items}' for i, items in enumerate(train_lst)]\n",
    "# val_lst2 = [f'{i}\\t{items}' for i, items in enumerate(val_lst)]\n",
    "# random.shuffle(train_lst2)\n",
    "# random.shuffle(val_lst2)\n",
    "\n",
    "# with open('train_lst.lst', 'w') as f:\n",
    "#     for line in train_lst2:\n",
    "#         f.write(f\"{line}\\n\")\n",
    "# with open('validation_lst.lst', 'w') as f:\n",
    "#     for line in val_lst2:\n",
    "#         f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9e53a",
   "metadata": {},
   "source": [
    "# Data Split/Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30bd95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = DIR_TRAIN, transform=transforms.Compose([\n",
    "    transforms.RandomRotation([-8, +8]),                                           # if augmentation\n",
    "    transforms.ColorJitter(brightness=0, contrast=0.4, saturation=0, hue=0),      # if augmentation\n",
    "    transforms.RandomHorizontalFlip(),                                            # if augmentation\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.676, 0.542, 0.519], std=[0.290, 0.226, 0.237])\n",
    "]))\n",
    "\n",
    "valid_dataset = ImageFolder(root = DIR_VAL, transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.676, 0.542, 0.519], std=[0.290, 0.226, 0.237])\n",
    "]))\n",
    "\n",
    "test_dataset = ImageFolder(root = DIR_TEST, transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.676, 0.542, 0.519], std=[0.290, 0.226, 0.237])\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce88db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size = int(0.5 * len(test_dataset))\n",
    "# valid_size = len(test_dataset) - test_size\n",
    "# valid_dataset, test_dataset = torch.utils.data.random_split(test_dataset, \n",
    "#                                                             [valid_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78fe70",
   "metadata": {},
   "source": [
    "# Train/Val Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "322e0916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/w210env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=24)\n",
    "dataloaders_dict['val'] = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=24, drop_last=False)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=24, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba257ae-6f13-46e3-a1c3-3e7cf3cdb74e",
   "metadata": {},
   "source": [
    "# LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e82e80-bdb7-4b28-9f77-ae2078a4c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 5 #100\n",
    "\n",
    "model = models.resnet50(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, len(classes), bias=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-7,\n",
    "    # weight_decay=1e-2\n",
    ")\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(dataloaders_dict['train'], \n",
    "                     end_lr=1, num_iter=100)\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0ec66",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:               \n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                #update_bn_stats(model=model, data_loader=dataloaders[phase])  # if update_bn_stats\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                      # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "               # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "   \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ffbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f'Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}')    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y - find the img from class x labelled as class y \n",
    "def test(model, dl, x, y, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    images_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images_list.append(images.cpu().numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "    \n",
    "    for n in range(60):\n",
    "        for i in range(32):\n",
    "            if (true_labels[n][i] == x)  & (predictions[n][i] == y):\n",
    "                #inv_tensor = inv_normalize(image_list[n][i]])\n",
    "                plt.imshow(np.transpose(images_list[n][i], (1, 2, 0)))\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d92480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 5 #100\n",
    "\n",
    "model = models.resnet50(weights='DEFAULT')\n",
    "model.fc = nn.Linear(2048, len(classes), bias=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=5.59E-04\n",
    ")\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'{data_split}_resnet50'\n",
    "torch.save(model, f'model/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f'model/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef92d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, predictions = test_model(model, dataloader_test, normalize=True)\n",
    "c_matrix = confusion_matrix(true_labels, predictions, normalize='true')\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Confusion matrix\")\n",
    "sns.heatmap(c_matrix, cmap='Blues', annot=True, xticklabels=classes, yticklabels=classes, fmt='.1%', cbar=True)\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('true labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0995a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # False prediction\n",
    "# test(model, dataloader_test, 2, 0) #(potentially malignant skin tumors, non-cancerous skin condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a24cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Correct prediction of autoimmune disorder\n",
    "# test(model, dataloader_test, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trace model\n",
    "\n",
    "# # must be the same size a minibatch with 1 example image\n",
    "# example = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# # move model back to cpu, do tracing, and optimize\n",
    "# model_conv = model.to('cpu')\n",
    "# traced_script_module = torch.jit.trace(model_conv, example)\n",
    "# torchscript_model_optimized = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "# # save optimized model for mobile\n",
    "# PATH = f'model/{model_name}_traced.pt'\n",
    "# torchscript_model_optimized.save(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c1727-8ab6-4999-a6f1-d4309288a8c5",
   "metadata": {},
   "source": [
    "# Conversion from PyTorch to CoreML\n",
    "https://github.com/vincentfpgarcia/from-pytorch-to-coreml/blob/master/step6_part1.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d2b62-c4c1-45c2-91c1-e83d09540a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "from coremltools.converters import ClassifierConfig\n",
    "\n",
    "classifier_config = ClassifierConfig(class_labels=class_list)\n",
    "\n",
    "model = torch.load(f'model/{model_name}.pt')\n",
    "\n",
    "# Create dummy input\n",
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "model_conv = model.to('cpu')\n",
    "\n",
    "# Trace the model\n",
    "traced_model = torch.jit.trace(model_conv, dummy_input)\n",
    "\n",
    "# Create the input image type\n",
    "input_image = ct.ImageType(name=\"my_input\", shape=(1, 3, 224, 224), scale=1/255)\n",
    "\n",
    "# Convert the model\n",
    "coreml_model = ct.convert(traced_model, inputs=[input_image], classifier_config=classifier_config)\n",
    "\n",
    "# Modify the output's name to \"my_output\" in the spec\n",
    "spec = coreml_model.get_spec()\n",
    "ct.utils.rename_feature(spec, \"var_840\", \"my_output\")\n",
    "\n",
    "# Re-create the model from the updated spec\n",
    "coreml_model_updated = ct.models.MLModel(spec)\n",
    "\n",
    "# Save the CoreML model\n",
    "coremlmodel_name = 'skindiseases5'\n",
    "coreml_model_updated.save(f'model/{coremlmodel_name}.mlmodel')\n",
    "\n",
    "# Load the CoreML model\n",
    "model =  ct.models.MLModel(f'model/{coremlmodel_name}.mlmodel')\n",
    "\n",
    "# Display its specifications\n",
    "print()\n",
    "print(model)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# classes\n",
    "classes = ['Benign Marking or Mole',\n",
    "           'Non-Cancerous Skin Condition',\n",
    "           'Potentially Malignant Skin Tumors', \n",
    "           'Toxin, Fungal, Bug, Viral, or Bacterial Infections',\n",
    "           'Unclassified']\n",
    "\n",
    "# Load the test image\n",
    "image = Image.open('inference/Potentially Malignant Skin Tumors/melanoma.jpeg')\n",
    "\n",
    "# Prediction vector as a numpy array\n",
    "pred = model.predict({'my_input': image.resize((224, 224))})\n",
    "pred = pred['my_output']\n",
    "pred = pred.squeeze()\n",
    "\n",
    "# Display the most probable class\n",
    "idx = pred.argmax()\n",
    "print('Predicted class : %d (%s)' % (idx, classes[idx]))\n",
    "pred['classLabel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f91f72",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = ImageFolder(root = 'inference/', transform=transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.676, 0.542, 0.519], std=[0.290, 0.226, 0.237])\n",
    "]))\n",
    "\n",
    "dataloader_inference = DataLoader(inference_dataset, batch_size=1, \n",
    "                                  shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "def inference_model(model, dl, normalize=True):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    # device = torch.device('cpu')\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dl:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs.data,-1)        \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predictions.append(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            num_correct += (predicted == labels).sum()\n",
    "        print(f'Inference Accuracy of the model: {float(num_correct)/float(total)*100:.2f}')    \n",
    "        true_labels = np.hstack(true_labels)\n",
    "        predictions = np.hstack(predictions)\n",
    "\n",
    "    return true_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(f'model/{model_name}_traced.pt')\n",
    "model = torch.load(f'model/{model_name}.pt')\n",
    "true_labels, predictions = inference_model(model, dataloader_inference, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -czf model/model.tar.gz model/merged_resnet50.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a4af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 cp model/model.tar.gz s3://rubyhan-w210-datasets/model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w210env:Python",
   "language": "python",
   "name": "conda-env-w210env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
