{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB6QjlVmr01i"
   },
   "source": [
    "# Modeling - First Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Byvs21KGrutm"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVEzW45qsn4t"
   },
   "source": [
    "### Installs, Packages, Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUgahMpfsKKF",
    "outputId": "d92d915c-d86b-48fb-e208-1db91d303b74"
   },
   "outputs": [],
   "source": [
    "# %pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hGcQYrTsrhNM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# python libraties\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# import imblearn\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import ipywidgets\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# # google drive\n",
    "# from google.colab import drive # Connect colab to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QdXZmteXsArn"
   },
   "outputs": [],
   "source": [
    "# Set Seeds\n",
    "seed = 99 # go Aaron Judge!\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtiFA177sreH"
   },
   "source": [
    "### Mount to Google drive to connect to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4aqVfhAsqso",
    "outputId": "fa6a3d9f-d152-45a3-ae13-70b3ea85d61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n",
      "/drive/.shortcut-targets-by-id/1oLqejM9KnDiIgUupEGkxGM3_vdqboxlI/W210 - Capstone\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/drive') \n",
    "%cd /drive/MyDrive/W210 - Capstone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEnlutDO2P29",
    "outputId": "ddbcf91c-41b5-42d3-82ed-39994c083b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34marchive\u001b[0m/                      \u001b[01;34mdiverse_stanford\u001b[0m/           \u001b[01;34mkaggle\u001b[0m/\n",
      "'Data Classification.gsheet'   \u001b[01;34mdiverse_stanford_resized\u001b[0m/   problems.csv\n",
      " data_dictionary.csv           full_data.csv               problems.gsheet\n",
      " data_dictionary.gsheet        \u001b[01;34mISIC_2018\u001b[0m/                  \u001b[01;34mUCI\u001b[0m/\n",
      " \u001b[01;34mdermnet\u001b[0m/                      \u001b[01;34mISIC_2020\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "H9mbVDYjtMR3"
   },
   "outputs": [],
   "source": [
    "data_dir = './Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "576JOVVyzMBp"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rO4tFvUP2aMa"
   },
   "source": [
    "### Load in full_csv which has all of the image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d3orkAJ42dxl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Found credentials from IAM Role: EC2S3FullAccess\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "s3_path = f's3://rubyhan-w210-datasets/full_data.csv'\n",
    "data = wr.s3.read_csv(path=s3_path, index_col=0).rename(columns={'duplicated':'duplicate', 'class':'label'})\n",
    "# data = pd.read_csv(data_dir + 'full_data.csv', index_col = 0).rename(columns = {'duplicated': 'duplicate', 'class':'label'})\n",
    "data['label_idx'] = pd.Categorical(data['label']).codes\n",
    "small_data = data.sample(n = 1000, random_state = seed)\n",
    "\n",
    "dev_state = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BFEmXBLRqyDM"
   },
   "outputs": [],
   "source": [
    "if dev_state:\n",
    "    data = small_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bk97ZrtoCVZ"
   },
   "source": [
    "### Get our final train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "m6W3aAwJnZRj"
   },
   "outputs": [],
   "source": [
    "train_df = data[data.dataset == 'train'].reset_index(drop = True)\n",
    "val_df = data[data.dataset == 'val'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b67w2_Joopms"
   },
   "outputs": [],
   "source": [
    "# logging.info(\"df train\"+str(df_train.shape))\n",
    "# logging.info(\"df val\"+str(df_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TaPtH1nqVCm"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YrnSBPziozXl"
   },
   "outputs": [],
   "source": [
    "# feature_extract is a boolean that defines if we are finetuning or feature extracting. \n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OZqprmSVqoIn"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18, resnet34, resnet50, resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet121\n",
    "        \"\"\"\n",
    "#         model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        model_ft = models.densenet201(pretrained=use_pretrained)\n",
    "        print(type(model_ft))\n",
    "        print(feature_extract)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "        \n",
    "    elif model_name == 'efficientnet':\n",
    "        model_ft = EfficientNet.from_pretrained('efficientnet-b7',num_classes=num_classes)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "\n",
    "#         # Handle the primary net\n",
    "#         num_ftrs = model_ft.fc.in_features\n",
    "#         model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 600\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCrm79KrsM4Q"
   },
   "source": [
    "Set up the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHfVOZMnq4QB",
    "outputId": "d8f2af0d-58d6-4aa6-d112-84c1734266b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Type: Tesla T4\n",
      "GPU Count: 1\n"
     ]
    }
   ],
   "source": [
    "print('GPU Type:', torch.cuda.get_device_name())\n",
    "print('GPU Count:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k-MDKEJrhxm",
    "outputId": "e99f112a-de59-4d91-c5b6-f10da572605e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lBHrD3vqpUJ",
    "outputId": "83b3eaa0-e560-4f32-f312-530724c27de5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015978574752807617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 102530333,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f8f27e18774123b3cdd88ab222c646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See notes in ln 498-500: https://github.com/abajaj25/MNIST-Skin-Cancer-with-Jetson/blob/main/notebooks/Final_Model/modeling-images-only-efficient.py\n",
    "# resnet,vgg,densenet,inception\n",
    "model_name = 'resnet' # 'efficientnet'\n",
    "num_classes = len(data.label.unique())\n",
    "feature_extract = False\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# # Define the device:\n",
    "device = torch.device('cuda:0')\n",
    "# # Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jewnveQy1FN"
   },
   "source": [
    "Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "19UAI6QbR-xg"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xJ7lgOfPw8n7"
   },
   "outputs": [],
   "source": [
    "# # using torch vision 'transforms'\n",
    "# train_transform = transforms.Compose([\n",
    "#                                         transforms.Resize((input_size,input_size)),\n",
    "#                                     #   transforms.RandomHorizontalFlip(),\n",
    "#                                     #   transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "#                                     #   transforms.RandomCrop(size=(input_size,input_size)),\n",
    "# #                                       transforms.RandomInvert(), transforms.RandomPosterize(bits=2),\n",
    "# #                                       transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "# #                                       transforms.RandomSolarize(threshold=192.0),\n",
    "# #                                       transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "#                                         transforms.ToTensor(), \n",
    "#                                     #   transforms.Normalize(norm_mean, norm_std)\n",
    "#                                       ])\n",
    "# # define the transformation of the val images.\n",
    "# val_transform = transforms.Compose([\n",
    "#                                     transforms.Resize((input_size,input_size)), \n",
    "#                                     transforms.ToTensor(),\n",
    "#                                     # transforms.Normalize(norm_mean, norm_std)\n",
    "#                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "L_7ROxXWKtfZ"
   },
   "outputs": [],
   "source": [
    "# using torch vision 'transforms'\n",
    "train_transform = transforms.Compose([\n",
    "                                        transforms.Resize(255),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                    #   transforms.RandomHorizontalFlip(),\n",
    "                                    #   transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                    #   transforms.RandomCrop(size=(input_size,input_size)),\n",
    "#                                       transforms.RandomInvert(), transforms.RandomPosterize(bits=2),\n",
    "#                                       transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "#                                       transforms.RandomSolarize(threshold=192.0),\n",
    "#                                       transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=[.541, .414, .382], std=[.256,.215,.209])\n",
    "                                      ])\n",
    "# define the transformation of the val images.\n",
    "val_transform = transforms.Compose([\n",
    "                                        transforms.Resize(255),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=[.541, .414, .382], std=[.256,.215,.209])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnigUvm8scEp"
   },
   "source": [
    "Pytorch Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "esg9Jg4wsHgK"
   },
   "outputs": [],
   "source": [
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index]).convert('RGB')\n",
    "        \n",
    "        y = torch.tensor(int(self.df['label_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "he9xbEYpst1X"
   },
   "outputs": [],
   "source": [
    "# Only selecting the columns we need from train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TZfBVOjo0L4N"
   },
   "outputs": [],
   "source": [
    "# Image.open(train['path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KRu51Xqsuiy2"
   },
   "outputs": [],
   "source": [
    "model_cols = ['path', 'label', 'label_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WCz_GTrrx51v"
   },
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0rn7lX-8sjQi"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[model_cols].reset_index(drop = True)\n",
    "val_df = val_df[model_cols].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twmPqhoWskPV",
    "outputId": "d8ef5168-9310-49f3-a9ed-67a2604dd41e"
   },
   "outputs": [],
   "source": [
    "training_set = HAM10000(train_df, transform = train_transform)\n",
    "train_loader = DataLoader(training_set, batch_size= 64, \n",
    "                          shuffle=True, num_workers=24)\n",
    "\n",
    "val_set = HAM10000(val_df, transform = val_transform)\n",
    "val_loader = DataLoader(val_set, batch_size= 64, \n",
    "                          shuffle=False, num_workers=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3MmauKD0s6Mi"
   },
   "outputs": [],
   "source": [
    "# Set model params\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZGBi_-2wEk8"
   },
   "source": [
    "Class to Track metrics during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "TcIjhtk_u6UO"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_HiMEG8wN-x"
   },
   "source": [
    "Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cR1k9diYwLf5"
   },
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "#         if (i + 1) % 1 == 0:\n",
    "            logging.info(f'[epoch {epoch}], [iter {i+1} of {len(train_loader)}],[train loss {train_loss.avg:.5f}], [train acc {train_acc.avg:.5f}]')\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjoA-pKzwSHn"
   },
   "source": [
    "Define val function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NVFDywvCwQqD"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    logging.info('------------------------------------------------------------')\n",
    "    logging.info(f'[epoch {epoch}], [val loss {val_loss.avg:.5f}], [val acc {val_acc.avg:.5f}]')\n",
    "    logging.info('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaUNPyrOwYnP"
   },
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nszOjE3gOP-l",
    "outputId": "09396458-72ea-45b8-84bb-a471c78c73f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:[epoch 1], [iter 100 of 731],[train loss 1.13925], [train acc 0.56250]\n",
      "INFO:[epoch 1], [iter 200 of 731],[train loss 0.99614], [train acc 0.62555]\n",
      "INFO:[epoch 1], [iter 300 of 731],[train loss 0.91830], [train acc 0.65568]\n",
      "INFO:[epoch 1], [iter 400 of 731],[train loss 0.87379], [train acc 0.67121]\n",
      "INFO:[epoch 1], [iter 500 of 731],[train loss 0.83957], [train acc 0.68378]\n",
      "INFO:[epoch 1], [iter 600 of 731],[train loss 0.81768], [train acc 0.69167]\n",
      "INFO:[epoch 1], [iter 700 of 731],[train loss 0.79829], [train acc 0.69893]\n",
      "INFO:------------------------------------------------------------\n",
      "INFO:[epoch 1], [val loss 0.66564], [val acc 0.75085]\n",
      "INFO:------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1 :\n",
      "*****************************************************\n",
      "Complete in 9m 13s\n",
      "best record: [epoch 1], [val loss 0.66564], [val acc 0.75085]\n",
      "*****************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:[epoch 2], [iter 100 of 731],[train loss 0.66114], [train acc 0.75047]\n",
      "INFO:[epoch 2], [iter 200 of 731],[train loss 0.63706], [train acc 0.75859]\n",
      "INFO:[epoch 2], [iter 300 of 731],[train loss 0.63842], [train acc 0.75682]\n",
      "INFO:[epoch 2], [iter 400 of 731],[train loss 0.63758], [train acc 0.75793]\n",
      "INFO:[epoch 2], [iter 500 of 731],[train loss 0.63218], [train acc 0.76003]\n",
      "INFO:[epoch 2], [iter 600 of 731],[train loss 0.63291], [train acc 0.76013]\n",
      "INFO:[epoch 2], [iter 700 of 731],[train loss 0.63014], [train acc 0.76103]\n",
      "INFO:------------------------------------------------------------\n",
      "INFO:[epoch 2], [val loss 0.61106], [val acc 0.76977]\n",
      "INFO:------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 2 :\n",
      "*****************************************************\n",
      "Complete in 9m 36s\n",
      "best record: [epoch 2], [val loss 0.61106], [val acc 0.76977]\n",
      "*****************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:[epoch 3], [iter 100 of 731],[train loss 0.60015], [train acc 0.77469]\n",
      "INFO:[epoch 3], [iter 200 of 731],[train loss 0.59006], [train acc 0.77891]\n",
      "INFO:[epoch 3], [iter 300 of 731],[train loss 0.58946], [train acc 0.77833]\n",
      "INFO:[epoch 3], [iter 400 of 731],[train loss 0.58725], [train acc 0.77832]\n",
      "INFO:[epoch 3], [iter 500 of 731],[train loss 0.58296], [train acc 0.78006]\n",
      "INFO:[epoch 3], [iter 600 of 731],[train loss 0.58283], [train acc 0.77997]\n",
      "INFO:[epoch 3], [iter 700 of 731],[train loss 0.58001], [train acc 0.78087]\n",
      "INFO:------------------------------------------------------------\n",
      "INFO:[epoch 3], [val loss 0.58303], [val acc 0.77859]\n",
      "INFO:------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 3 :\n",
      "*****************************************************\n",
      "Complete in 9m 3s\n",
      "best record: [epoch 3], [val loss 0.58303], [val acc 0.77859]\n",
      "*****************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:[epoch 4], [iter 100 of 731],[train loss 0.54155], [train acc 0.79734]\n",
      "INFO:[epoch 4], [iter 200 of 731],[train loss 0.54420], [train acc 0.79695]\n",
      "INFO:[epoch 4], [iter 300 of 731],[train loss 0.54463], [train acc 0.79766]\n",
      "INFO:[epoch 4], [iter 400 of 731],[train loss 0.54288], [train acc 0.79914]\n",
      "INFO:[epoch 4], [iter 500 of 731],[train loss 0.54261], [train acc 0.79966]\n",
      "INFO:[epoch 4], [iter 600 of 731],[train loss 0.54192], [train acc 0.79911]\n",
      "INFO:[epoch 4], [iter 700 of 731],[train loss 0.54051], [train acc 0.79955]\n",
      "INFO:------------------------------------------------------------\n",
      "INFO:[epoch 4], [val loss 0.56770], [val acc 0.78667]\n",
      "INFO:------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 4 :\n",
      "*****************************************************\n",
      "Complete in 9m 36s\n",
      "best record: [epoch 4], [val loss 0.56770], [val acc 0.78667]\n",
      "*****************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:[epoch 5], [iter 100 of 731],[train loss 0.50498], [train acc 0.81422]\n",
      "INFO:[epoch 5], [iter 200 of 731],[train loss 0.50005], [train acc 0.81367]\n",
      "INFO:[epoch 5], [iter 300 of 731],[train loss 0.50211], [train acc 0.81229]\n",
      "INFO:[epoch 5], [iter 400 of 731],[train loss 0.50566], [train acc 0.81074]\n",
      "INFO:[epoch 5], [iter 500 of 731],[train loss 0.50581], [train acc 0.81100]\n",
      "INFO:[epoch 5], [iter 600 of 731],[train loss 0.50436], [train acc 0.81159]\n",
      "INFO:[epoch 5], [iter 700 of 731],[train loss 0.50578], [train acc 0.81036]\n",
      "INFO:------------------------------------------------------------\n",
      "INFO:[epoch 5], [val loss 0.54999], [val acc 0.79549]\n",
      "INFO:------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 5 :\n",
      "*****************************************************\n",
      "Complete in 9m 38s\n",
      "best record: [epoch 5], [val loss 0.54999], [val acc 0.79549]\n",
      "*****************************************************\n",
      "\n",
      "Total run Complete in 47m 5s\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 5\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "print(\"Starting Training\")\n",
    "total_since = time.time()\n",
    "for epoch in range(1, epoch_num+1):\n",
    "\n",
    "    # timing\n",
    "    since = time.time()\n",
    "\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "    # torch.save(model.state_dict(), '/data/mnist_skin/model_efficientnet_augment.pth')\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print('\\nEPOCH', epoch, \":\")\n",
    "    print('*****************************************************')\n",
    "    print('Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]')\n",
    "    print('*****************************************************')\n",
    "    # print(logging.info('*****************************************************'))\n",
    "    # print(logging.info(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]'))\n",
    "    # print(logging.info('*****************************************************'))\n",
    "\n",
    "total_time_elapsed = time.time() - total_since\n",
    "print('\\nTotal run Complete in {:.0f}m {:.0f}s'.format(total_time_elapsed // 60, total_time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lVAehidNNTNa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954931972789115"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGJg7v7jwVfE"
   },
   "outputs": [],
   "source": [
    "# epoch_num = 1\n",
    "# best_val_acc = 0\n",
    "# total_loss_val, total_acc_val = [],[]\n",
    "# logging.info(\"Starting Training\")\n",
    "# for epoch in range(1, epoch_num+1):\n",
    "#     loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "# #     print('1')\n",
    "#     loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "# #     print('2')\n",
    "#     total_loss_val.append(loss_val)\n",
    "# #     print('3')\n",
    "#     total_acc_val.append(acc_val)\n",
    "# #     print('4')\n",
    "#     if acc_val > best_val_acc:\n",
    "# #         print('5')\n",
    "#         best_val_acc = acc_val\n",
    "#         # torch.save(model.state_dict(), '/data/mnist_skin/model_efficientnet_augment.pth')\n",
    "#         logging.info('*****************************************************')\n",
    "#         logging.info(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]')\n",
    "#         logging.info('*****************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kab9VpS9wZac"
   },
   "outputs": [],
   "source": [
    "# Check out \"making the most of your colab subscription\" https://colab.research.google.com/notebooks/pro.ipynb#scrollTo=65MSuHKqNeBZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'merged_resnet50'\n",
    "torch.save(model, f'model/{model_name}.pt')\n",
    "model = torch.load(f'model/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace model\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "# must be the same size a minibatch with 1 example image\n",
    "example = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# move model back to cpu, do tracing, and optimize\n",
    "model_conv = model.to('cpu')\n",
    "traced_script_module = torch.jit.trace(model_conv, example)\n",
    "torchscript_model_optimized = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "# save optimized model for mobile\n",
    "PATH = f'model/{model_name}_traced.pt'\n",
    "torchscript_model_optimized.save(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
