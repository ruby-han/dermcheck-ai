{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB6QjlVmr01i"
   },
   "source": [
    "# Modeling - First Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Byvs21KGrutm"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVEzW45qsn4t"
   },
   "source": [
    "### Installs, Packages, Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4691,
     "status": "ok",
     "timestamp": 1665619503062,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "rUgahMpfsKKF",
    "outputId": "0e42ef16-9cbc-4c21-8add-507a0f4502f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting efficientnet_pytorch\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.12.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (4.1.1)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=b58ce8c31162b56d77fe6ed44061c9009ea1131cff4d50e193eaf9283ed31ac8\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1\n"
     ]
    }
   ],
   "source": [
    "%pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3266,
     "status": "ok",
     "timestamp": 1665619506323,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "hGcQYrTsrhNM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# python libraties\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "# import imblearn\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import ipywidgets\n",
    "\n",
    "# pytorch libraries\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# google drive\n",
    "from google.colab import drive # Connect colab to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1665619506323,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "QdXZmteXsArn"
   },
   "outputs": [],
   "source": [
    "# Set Seeds\n",
    "seed = 99 # go Aaron Judge!\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtiFA177sreH"
   },
   "source": [
    "### Mount to Google drive to connect to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18359,
     "status": "ok",
     "timestamp": 1665619529434,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "L4aqVfhAsqso",
    "outputId": "e536702f-17b9-4981-bfe0-05aa7de93304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /drive\n",
      "/drive/.shortcut-targets-by-id/1oLqejM9KnDiIgUupEGkxGM3_vdqboxlI/W210 - Capstone\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/drive') \n",
    "%cd /drive/MyDrive/W210 - Capstone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1665619507894,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "CEnlutDO2P29"
   },
   "outputs": [],
   "source": [
    "%ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1665619529435,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "H9mbVDYjtMR3"
   },
   "outputs": [],
   "source": [
    "data_dir = './Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "576JOVVyzMBp"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rO4tFvUP2aMa"
   },
   "source": [
    "### Load in full_csv which has all of the image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1665622238025,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "d3orkAJ42dxl"
   },
   "outputs": [],
   "source": [
    "dev_state = False\n",
    "dev_sample = 15000\n",
    "\n",
    "data = pd.read_csv(data_dir + 'full_data.csv', index_col = 0).rename(columns = {'duplicated': 'duplicate', 'class':'label'})\n",
    "data = data[data['label'] != 'Autoimmue Disorder']\n",
    "data['label_idx'] = pd.Categorical(data['label']).codes\n",
    "small_data = data.sample(n = dev_sample, random_state = seed)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1665622239414,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "0sVad-XkuhSW"
   },
   "outputs": [],
   "source": [
    "split = 'split_1'\n",
    "data.rename(columns = {'dataset':'split_0', split:'dataset'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1665622258295,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "BFEmXBLRqyDM"
   },
   "outputs": [],
   "source": [
    "if dev_state:\n",
    "  data = small_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bk97ZrtoCVZ"
   },
   "source": [
    "### Get our final train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665622258535,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "m6W3aAwJnZRj"
   },
   "outputs": [],
   "source": [
    "train_df = data[data.dataset == 'train'].reset_index(drop = True)\n",
    "val_df = data[data.dataset == 'val'].reset_index(drop = True)\n",
    "test_df = data[data.dataset == 'test'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665622258535,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "b67w2_Joopms"
   },
   "outputs": [],
   "source": [
    "# logging.info(\"df train\"+str(df_train.shape))\n",
    "# logging.info(\"df val\"+str(df_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TaPtH1nqVCm"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zV8Kq9caqc_m"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665622258535,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "ZJESBIlpqcCr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665622258536,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "YrnSBPziozXl"
   },
   "outputs": [],
   "source": [
    "# feature_extract is a boolean that defines if we are finetuning or feature extracting. \n",
    "# If feature_extract = False, the model is finetuned and all model parameters are updated. \n",
    "# If feature_extract = True, only the last layer parameters are updated, the others remain fixed.\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665622258709,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "OZqprmSVqoIn"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18, resnet34, resnet50, resnet101\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet121\n",
    "        \"\"\"\n",
    "#         model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        model_ft = models.densenet201(pretrained=use_pretrained)\n",
    "        print(type(model_ft))\n",
    "        print(feature_extract)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "        \n",
    "    elif model_name == 'efficientnet':\n",
    "        model_ft = EfficientNet.from_pretrained('efficientnet-b7',num_classes=num_classes)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "\n",
    "#         # Handle the primary net\n",
    "#         num_ftrs = model_ft.fc.in_features\n",
    "#         model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 600\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCrm79KrsM4Q"
   },
   "source": [
    "Set up the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1665622258709,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "FHfVOZMnq4QB",
    "outputId": "5db634ad-8de9-4a39-ae53-9130ddb16ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Type: A100-SXM4-40GB\n",
      "GPU Count: 1\n"
     ]
    }
   ],
   "source": [
    "print('GPU Type:', torch.cuda.get_device_name())\n",
    "print('GPU Count:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665622258709,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "4k-MDKEJrhxm",
    "outputId": "19069c75-8e8e-4344-aa53-e0b30265429b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1665622259172,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "1lBHrD3vqpUJ",
    "outputId": "3406c526-2a5d-4b08-d93c-23d03b4e097f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# See notes in ln 498-500: https://github.com/abajaj25/MNIST-Skin-Cancer-with-Jetson/blob/main/notebooks/Final_Model/modeling-images-only-efficient.py\n",
    "# resnet,vgg,densenet,inception\n",
    "model_name = 'resnet' # 'efficientnet'\n",
    "num_classes = len(data.label.unique())\n",
    "feature_extract = False\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "# # Define the device:\n",
    "device = torch.device('cuda:0')\n",
    "# # Put the model on the device:\n",
    "model = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jewnveQy1FN"
   },
   "source": [
    "Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1665622259540,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "19UAI6QbR-xg"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1665622259540,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "xJ7lgOfPw8n7"
   },
   "outputs": [],
   "source": [
    "# # using torch vision 'transforms'\n",
    "# train_transform = transforms.Compose([\n",
    "#                                         transforms.Resize((input_size,input_size)),\n",
    "#                                     #   transforms.RandomHorizontalFlip(),\n",
    "#                                     #   transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "#                                     #   transforms.RandomCrop(size=(input_size,input_size)),\n",
    "# #                                       transforms.RandomInvert(), transforms.RandomPosterize(bits=2),\n",
    "# #                                       transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "# #                                       transforms.RandomSolarize(threshold=192.0),\n",
    "# #                                       transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "#                                         transforms.ToTensor(), \n",
    "#                                     #   transforms.Normalize(norm_mean, norm_std)\n",
    "#                                       ])\n",
    "# # define the transformation of the val images.\n",
    "# val_transform = transforms.Compose([\n",
    "#                                     transforms.Resize((input_size,input_size)), \n",
    "#                                     transforms.ToTensor(),\n",
    "#                                     # transforms.Normalize(norm_mean, norm_std)\n",
    "#                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1665622259541,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "L_7ROxXWKtfZ"
   },
   "outputs": [],
   "source": [
    "# using torch vision 'transforms'\n",
    "train_transform = transforms.Compose([\n",
    "                                        transforms.Resize(255),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                    #   transforms.RandomHorizontalFlip(),\n",
    "                                    #   transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                    #   transforms.RandomCrop(size=(input_size,input_size)),\n",
    "#                                       transforms.RandomInvert(), transforms.RandomPosterize(bits=2),\n",
    "#                                       transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "#                                       transforms.RandomSolarize(threshold=192.0),\n",
    "#                                       transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=[.541, .414, .382], std=[.256,.215,.209])\n",
    "                                      ])\n",
    "# define the transformation of the val images. also used for test\n",
    "val_transform = transforms.Compose([\n",
    "                                        transforms.Resize(255),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=[.541, .414, .382], std=[.256,.215,.209])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnigUvm8scEp"
   },
   "source": [
    "Pytorch Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665622259541,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "esg9Jg4wsHgK"
   },
   "outputs": [],
   "source": [
    "class HAM10000(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.df['path'][index]).convert('RGB')\n",
    "        \n",
    "        y = torch.tensor(int(self.df['label_idx'][index]))\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665622259541,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "he9xbEYpst1X"
   },
   "outputs": [],
   "source": [
    "# Only selecting the columns we need from train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665622259542,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "TZfBVOjo0L4N"
   },
   "outputs": [],
   "source": [
    "# Image.open(train['path'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665622259542,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "KRu51Xqsuiy2"
   },
   "outputs": [],
   "source": [
    "model_cols = ['path', 'label', 'label_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665622259542,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "WCz_GTrrx51v"
   },
   "outputs": [],
   "source": [
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665622259542,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "0rn7lX-8sjQi"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[model_cols].reset_index(drop = True)\n",
    "val_df = val_df[model_cols].reset_index(drop = True)\n",
    "test_df = test_df[model_cols].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665622259543,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "twmPqhoWskPV",
    "outputId": "433c2418-e002-4283-9358-d702602c2f93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "training_set = HAM10000(train_df, transform = train_transform)\n",
    "train_loader = DataLoader(training_set, batch_size= 64, \n",
    "                          shuffle=True, num_workers=24)\n",
    "\n",
    "val_set = HAM10000(val_df, transform = val_transform)\n",
    "val_loader = DataLoader(val_set, batch_size= 64, \n",
    "                          shuffle=False, num_workers=24)\n",
    "\n",
    "test_set = HAM10000(test_df, transform = val_transform)\n",
    "test_loader = DataLoader(test_set, batch_size= 64, \n",
    "                          shuffle=False, num_workers=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665622259543,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "3MmauKD0s6Mi"
   },
   "outputs": [],
   "source": [
    "# Set model params\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZGBi_-2wEk8"
   },
   "source": [
    "Class to Track metrics during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665622259543,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "TcIjhtk_u6UO"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_HiMEG8wN-x"
   },
   "source": [
    "Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665622259543,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "cR1k9diYwLf5"
   },
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 100 == 0:\n",
    "#         if (i + 1) % 1 == 0:\n",
    "            print(f'[epoch {epoch}], [iter {i+1} of {len(train_loader)}],[train loss {train_loss.avg:.5f}], [train acc {train_acc.avg:.5f}]')\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg\n",
    "    print('finished train data load')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjoA-pKzwSHn"
   },
   "source": [
    "Define val function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665622259544,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "NVFDywvCwQqD"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print(f'[epoch {epoch}], [val loss {val_loss.avg:.5f}], [val acc {val_acc.avg:.5f}]')\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665622259544,
     "user": {
      "displayName": "Gerrit Lensink",
      "userId": "14030898330788478401"
     },
     "user_tz": 420
    },
    "id": "i3hav7ENJDj2"
   },
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions_out = []\n",
    "\n",
    "    test_loss = AverageMeter()\n",
    "    test_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            # Save test output\n",
    "            predictions_out.append(prediction.cpu().numpy())\n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            test_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            test_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print(f'[test loss {test_loss.avg:.5f}], [test acc {test_acc.avg:.5f}]')\n",
    "    print('------------------------------------------------------------')\n",
    "    return test_loss.avg, test_acc.avg, predictions_out, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaUNPyrOwYnP"
   },
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJRXeTZDqtLA"
   },
   "source": [
    "## Train Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6u5sMnfz8Ga",
    "outputId": "947896df-a6a3-4b96-81be-eb7619e72322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "[epoch 1], [iter 100 of 658],[train loss 0.96839], [train acc 0.62906]\n",
      "[epoch 1], [iter 200 of 658],[train loss 0.80823], [train acc 0.69703]\n",
      "[epoch 1], [iter 300 of 658],[train loss 0.73678], [train acc 0.72479]\n",
      "[epoch 1], [iter 400 of 658],[train loss 0.68474], [train acc 0.74422]\n",
      "[epoch 1], [iter 500 of 658],[train loss 0.65381], [train acc 0.75503]\n",
      "[epoch 1], [iter 600 of 658],[train loss 0.62744], [train acc 0.76375]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'resnet_split1_3e'\n",
    "epoch_num = 3\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "print(\"Starting Training\")\n",
    "total_since = time.time()\n",
    "for epoch in range(1, epoch_num+1):\n",
    "\n",
    "    # timing\n",
    "    since = time.time()\n",
    "\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        torch.save(model, f'./Models/{model_name}.pt')\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print('\\nEPOCH', epoch, \":\")\n",
    "    print('*****************************************************')\n",
    "    print('Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]')\n",
    "    print('*****************************************************')\n",
    "    # print(logging.info('*****************************************************'))\n",
    "    # print(logging.info(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]'))\n",
    "    # print(logging.info('*****************************************************'))\n",
    "\n",
    "total_time_elapsed = time.time() - total_since\n",
    "print('\\nTotal run Complete in {:.0f}m {:.0f}s'.format(total_time_elapsed // 60, total_time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_aNMVhewqcE"
   },
   "source": [
    "#### Previous Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vq10pkH3vCcz"
   },
   "outputs": [],
   "source": [
    "# model_name = 'resnet_split3_3e'\n",
    "# epoch_num = 3\n",
    "# best_val_acc = 0\n",
    "# total_loss_val, total_acc_val = [],[]\n",
    "# print(\"Starting Training\")\n",
    "# total_since = time.time()\n",
    "# for epoch in range(1, epoch_num+1):\n",
    "\n",
    "#     # timing\n",
    "#     since = time.time()\n",
    "\n",
    "#     loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "#     total_loss_val.append(loss_val)\n",
    "#     total_acc_val.append(acc_val)\n",
    "\n",
    "#     if acc_val > best_val_acc:\n",
    "#         best_val_acc = acc_val\n",
    "#         torch.save(model, f'./Models/{model_name}.pt')\n",
    "    \n",
    "#     time_elapsed = time.time() - since\n",
    "\n",
    "#     print('\\nEPOCH', epoch, \":\")\n",
    "#     print('*****************************************************')\n",
    "#     print('Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#     print(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]')\n",
    "#     print('*****************************************************')\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "#     # print(logging.info(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]'))\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "\n",
    "# total_time_elapsed = time.time() - total_since\n",
    "# print('\\nTotal run Complete in {:.0f}m {:.0f}s'.format(total_time_elapsed // 60, total_time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dbl3KozEMAJv"
   },
   "outputs": [],
   "source": [
    "# model_name = 'resnet_15k_3e'\n",
    "# epoch_num = 3\n",
    "# best_val_acc = 0\n",
    "# total_loss_val, total_acc_val = [],[]\n",
    "# print(\"Starting Training\")\n",
    "# total_since = time.time()\n",
    "# for epoch in range(1, epoch_num+1):\n",
    "\n",
    "#     # timing\n",
    "#     since = time.time()\n",
    "\n",
    "#     loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "#     total_loss_val.append(loss_val)\n",
    "#     total_acc_val.append(acc_val)\n",
    "\n",
    "#     if acc_val > best_val_acc:\n",
    "#         best_val_acc = acc_val\n",
    "#         torch.save(model, f'./Models/{model_name}.pt')\n",
    "    \n",
    "#     time_elapsed = time.time() - since\n",
    "\n",
    "#     print('\\nEPOCH', epoch, \":\")\n",
    "#     print('*****************************************************')\n",
    "#     print('Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#     print(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]')\n",
    "#     print('*****************************************************')\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "#     # print(logging.info(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]'))\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "\n",
    "# total_time_elapsed = time.time() - total_since\n",
    "# print('\\nTotal run Complete in {:.0f}m {:.0f}s'.format(total_time_elapsed // 60, total_time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nszOjE3gOP-l"
   },
   "outputs": [],
   "source": [
    "# model_name = 'model_resnet_full'\n",
    "# epoch_num = 5\n",
    "# best_val_acc = 0\n",
    "# total_loss_val, total_acc_val = [],[]\n",
    "# print(\"Starting Training\")\n",
    "# total_since = time.time()\n",
    "# for epoch in range(1, epoch_num+1):\n",
    "\n",
    "#     # timing\n",
    "#     since = time.time()\n",
    "\n",
    "#     loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "#     total_loss_val.append(loss_val)\n",
    "#     total_acc_val.append(acc_val)\n",
    "\n",
    "#     if acc_val > best_val_acc:\n",
    "#         best_val_acc = acc_val\n",
    "#         torch.save(model, f'./Models/{model_name}.pt')\n",
    "    \n",
    "#     time_elapsed = time.time() - since\n",
    "\n",
    "#     print('\\nEPOCH', epoch, \":\")\n",
    "#     print('*****************************************************')\n",
    "#     print('Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#     print(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]')\n",
    "#     print('*****************************************************')\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "#     # print(logging.info(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]'))\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "\n",
    "# total_time_elapsed = time.time() - total_since\n",
    "# print('\\nTotal run Complete in {:.0f}m {:.0f}s'.format(total_time_elapsed // 60, total_time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVAehidNNTNa"
   },
   "outputs": [],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzIDVaq5I2bT"
   },
   "outputs": [],
   "source": [
    "# model_name = 'resnet_split2_3e'\n",
    "# epoch_num = 3\n",
    "# best_val_acc = 0\n",
    "# total_loss_val, total_acc_val = [],[]\n",
    "# print(\"Starting Training\")\n",
    "# total_since = time.time()\n",
    "# for epoch in range(1, epoch_num+1):\n",
    "\n",
    "#     # timing\n",
    "#     since = time.time()\n",
    "\n",
    "#     loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     loss_val, acc_val = validate(val_loader, model, criterion, optimizer, epoch)\n",
    "#     total_loss_val.append(loss_val)\n",
    "#     total_acc_val.append(acc_val)\n",
    "\n",
    "#     if acc_val > best_val_acc:\n",
    "#         best_val_acc = acc_val\n",
    "#         torch.save(model, f'./Models/{model_name}.pt')\n",
    "    \n",
    "#     time_elapsed = time.time() - since\n",
    "\n",
    "#     print('\\nEPOCH', epoch, \":\")\n",
    "#     print('*****************************************************')\n",
    "#     print('Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#     print(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]')\n",
    "#     print('*****************************************************')\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "#     # print(logging.info(f'best record: [epoch {epoch}], [val loss {loss_val:.5f}], [val acc {acc_val:.5f}]'))\n",
    "#     # print(logging.info('*****************************************************'))\n",
    "\n",
    "# total_time_elapsed = time.time() - total_since\n",
    "# print('\\nTotal run Complete in {:.0f}m {:.0f}s'.format(total_time_elapsed // 60, total_time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bkIMyMJq4hj"
   },
   "source": [
    "## Test/Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Xg3aZsGvMcA"
   },
   "outputs": [],
   "source": [
    "# model_name = 'model_resnet_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA4jtlf0IQx6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # model_in = torch.load(f'./Models/{model_name}.pth')\n",
    "# model.load_state_dict(torch.load(f'./Models/{model_name}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9YTFlp8q_q0"
   },
   "outputs": [],
   "source": [
    "# model_name = 'resnet_split3_3e'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m20u6LVTusYz"
   },
   "outputs": [],
   "source": [
    "# torch.save(model, './Models/test.pt')\n",
    "# model_in = torch.load('./Models/model_resnet_full.pt')\n",
    "model_in = torch.load(f'./Models/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xxg69C0GI_pj"
   },
   "outputs": [],
   "source": [
    "loss_test, acc_test, preds, labs = test(test_loader, model_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1Qk80IvPNJT"
   },
   "outputs": [],
   "source": [
    "true_labels = np.array(list(itertools.chain(*labs)))\n",
    "predictions = np.array(list(itertools.chain(*preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFWpwH16S1Hs"
   },
   "outputs": [],
   "source": [
    "correct = (true_labels == predictions.flatten())\n",
    "accur = correct.sum() / correct.size\n",
    "accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3dk2etNqzMY"
   },
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLsDjc_qnZg9"
   },
   "outputs": [],
   "source": [
    "labels_idx = np.sort(data.label_idx.unique())\n",
    "label_map = data[['label', 'label_idx']].drop_duplicates().sort_values('label_idx')\n",
    "label_dict = dict(zip(label_map.label_idx, label_map.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hxsVuL-owka"
   },
   "outputs": [],
   "source": [
    "labs = pd.Series(true_labels).map(label_dict)\n",
    "preds = pd.Series(predictions.flatten()).map(label_dict)\n",
    "labels = pd.Series(labels_idx).map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRAaw22hk1z1"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.concat([labs, \n",
    "           preds, \n",
    "           pd.Series(true_labels), \n",
    "           pd.Series(predictions.flatten())], axis = 1)\\\n",
    "           .rename(columns = {0:'lab', 1: 'pred', 2: 'lab_idx', 3: 'pred_idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-UmPGbDtnL9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjVwpTWqlH9f"
   },
   "outputs": [],
   "source": [
    "pred_df.to_pickle(f'./Models/{model_name}_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MvE5Sgxk47m"
   },
   "outputs": [],
   "source": [
    "d = pd.read_pickle(f'./Models/{model_name}_preds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22kpIHR4kF1A"
   },
   "outputs": [],
   "source": [
    "labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQ00A5VMl_Yt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09MnAAoxiMAK"
   },
   "outputs": [],
   "source": [
    "# c_matrix = confusion_matrix(labs, preds, normalize = 'true')\n",
    "# plt.title(\"Confusion matrix\")\n",
    "# sns.heatmap(c_matrix, cmap='Blues', annot=True, xticklabels=labels, yticklabels=labels, fmt='.1%', cbar=True)\n",
    "# plt.xlabel('predictions')\n",
    "# plt.ylabel('true labels')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFZEDo9wjDfk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
