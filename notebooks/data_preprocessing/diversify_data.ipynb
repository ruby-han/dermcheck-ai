{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e35bda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.image as mp_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b371bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 99 # go Aaron Judge!\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a85fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/teledermatologyAI_capstone\n"
     ]
    }
   ],
   "source": [
    "cd ../Data/data_overlay/overlayed_images_dermnet_ISIC_2018/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "347f68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = '/home/ec2-user/SageMaker/teledermatologyAI_capstone'\n",
    "blended_dir = '/Data/data_overlay'\n",
    "blended_p1 = '/overlayed_images_dermnet_ISIC_2018/'\n",
    "blended_p2 = '/overlayed_images_part_three/'\n",
    "blended_p3 = '/overlayed_images_part_two/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b80dd07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = glob(os.path.join(HOME + blended_dir + blended_p1, '*'+'.png'))\n",
    "p2 = glob(os.path.join(HOME + blended_dir + blended_p2, '*'+'.png'))\n",
    "p3 = glob(os.path.join(HOME + blended_dir + blended_p3, '*'+'.png'))\n",
    "diverse_paths = pd.Series(p1 + p2 + p3, name  = 'F6_path')\n",
    "diverse_ids = pd.Series([os.path.splitext(os.path.basename(i))[0] for i in blended_paths], name = 'image_id')\n",
    "\n",
    "# paths = pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6ff0df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "diverse_df = pd.concat([diverse_ids, diverse_paths], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c051ff17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/teledermatologyAI_capstone'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8bf8860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (7,11,12,13,14,15,16,17,18,19,20,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/ec2-user/SageMaker/teledermatologyAI_capstone/full_data_final_not_diverse.csv', index_col = 0)\n",
    "data.rename(columns = {'path': 'unaltered_path'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "940f0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data.merge(right = diverse_df, \n",
    "                 how = 'left', \n",
    "                 on = 'image_id')\n",
    "\n",
    "# # some of the ids don't have a diverse representation for some reason\n",
    "# # looks like this is fairly distributed given our splits of train/val/test\n",
    "# new[(new.F6_path.isna()) & (new.split_10.isna() == False)].split_10.value_counts()\n",
    "\n",
    "# # Also, looks like we may have not done this to stanford diverse, which is ok\n",
    "# new[(new.F6_path.isna()) & (new.split_10.isna() == False)].source.value_counts()\n",
    "\n",
    "# # For that reason, we need to subset the list of eligible IDs to be replaced with diverse images\n",
    "# # - Don't want stanford data, it's already diverse\n",
    "# # - Have to choose from data that has a diverse representation (path)\n",
    "# # - Applying this sampling based on split 8, because it was the most successful run\n",
    "\n",
    "ids_to_sample = new[(new.F6_path.isna() == False) & (new.split_8.isna() == False)]['image_id']\n",
    "ids_to_replace = ids_to_sample.sample(frac = .33, \n",
    "                                      replace = False, \n",
    "                                      random_state = seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8918adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new['path'] = np.where(new.image_id.isin(ids_to_replace), new.F6_path, new.unaltered_path)\n",
    "new['overlayed'] = np.where(new.image_id.isin(ids_to_replace), 1, 0)\n",
    "new.to_csv(f'{HOME}/full_data_final_diverse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7ad25134",
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder = ['image_id', 'diagnosis', 'age', 'sex', 'localization', 'source',\n",
    "           'severity', 'unaltered_path', 'F6_path', 'path', 'duplicate', \n",
    "           'overlayed', 'label_0', 'label_4', 'label_5', 'label_6', 'split_0', \n",
    "           'split_1', 'split_2', 'split_3', 'split_4', 'split_5', 'split_6', \n",
    "           'split_7', 'split_8', 'split_9','split_10']\n",
    "new = new[reorder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "65c369f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_csv(f'{HOME}/full_data_final_diverse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3ebf2a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23812\n",
       "1     7818\n",
       "Name: overlayed, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new[new.overlayed == 1].split_9.value_counts()\n",
    "# new[new.split_9.isna() == False].overlayed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f014fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests = new.path.sample(3, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "85364c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipath = './Data/ISIC_2019/ISIC_2019_Training_Input/ISIC_0000000.jpg'\n",
    "# ipath2 = '/home/ec2-user/SageMaker/teledermatologyAI_capstone/Data/data_overlay/overlayed_images_dermnet_ISIC_2018/ISIC_0028790.png'\n",
    "\n",
    "# ipath2 = tests.iloc[0]\n",
    "# image = mp_image.imread(ipath2)\n",
    "# # imshow(image)\n",
    "# fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (15, 15))\n",
    "# axes.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3262fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
